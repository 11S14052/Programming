{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from edward.models import Normal, Categorical\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"C:/Users/Wahyu Nainggolan/Documents/TA Gue/TA_2/Implementasi/fix/preprocessing_data\"))\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, Imputer,StandardScaler\n",
    "from tqdm import tqdm\n",
    "from preprocessing_data import preprocessingData_toDBN\n",
    "from preprocessing_data import preprocessingData_onehotencoder\n",
    "#from preprocessing_data import preprocessingData_onehotencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/2240 with 0 missing, elapsed time: 1.063\n",
      "Imputing row 101/2240 with 0 missing, elapsed time: 1.063\n",
      "Imputing row 201/2240 with 0 missing, elapsed time: 1.078\n",
      "Imputing row 301/2240 with 0 missing, elapsed time: 1.078\n",
      "Imputing row 401/2240 with 0 missing, elapsed time: 1.078\n",
      "Imputing row 501/2240 with 0 missing, elapsed time: 1.094\n",
      "Imputing row 601/2240 with 0 missing, elapsed time: 1.094\n",
      "Imputing row 701/2240 with 0 missing, elapsed time: 1.094\n",
      "Imputing row 801/2240 with 0 missing, elapsed time: 1.094\n",
      "Imputing row 901/2240 with 0 missing, elapsed time: 1.109\n",
      "Imputing row 1001/2240 with 0 missing, elapsed time: 1.125\n",
      "Imputing row 1101/2240 with 0 missing, elapsed time: 1.125\n",
      "Imputing row 1201/2240 with 0 missing, elapsed time: 1.125\n",
      "Imputing row 1301/2240 with 0 missing, elapsed time: 1.141\n",
      "Imputing row 1401/2240 with 0 missing, elapsed time: 1.141\n",
      "Imputing row 1501/2240 with 9 missing, elapsed time: 1.172\n",
      "Imputing row 1601/2240 with 9 missing, elapsed time: 1.188\n",
      "Imputing row 1701/2240 with 9 missing, elapsed time: 1.203\n",
      "Imputing row 1801/2240 with 0 missing, elapsed time: 1.219\n",
      "Imputing row 1901/2240 with 9 missing, elapsed time: 1.234\n",
      "Imputing row 2001/2240 with 9 missing, elapsed time: 1.250\n",
      "Imputing row 2101/2240 with 9 missing, elapsed time: 1.266\n",
      "Imputing row 2201/2240 with 9 missing, elapsed time: 1.281\n",
      "[KNN] Warning: 198/40320 still missing after imputation, replacing with 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wahyu Nainggolan\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "world_cup_2014 = pd.read_csv(\"C:/Users/Wahyu Nainggolan/Documents/TA Gue/TA_2/Implementasi/Data/2018/data_train/data_full_train_2018.csv\", delimiter= ',')\n",
    "independent_data_train,dependent_data_train= preprocessingData_toDBN(world_cup_2014) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>HTRF</th>\n",
       "      <th>THFP</th>\n",
       "      <th>PHPAR</th>\n",
       "      <th>PHSPAR</th>\n",
       "      <th>PHPSAR</th>\n",
       "      <th>PHDAR</th>\n",
       "      <th>...</th>\n",
       "      <th>PHAAR</th>\n",
       "      <th>ATRF</th>\n",
       "      <th>TAFP</th>\n",
       "      <th>PAPAR</th>\n",
       "      <th>PASPAR</th>\n",
       "      <th>PAPSAR</th>\n",
       "      <th>PADAR</th>\n",
       "      <th>PATSA</th>\n",
       "      <th>PADBAR</th>\n",
       "      <th>PAAAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greece</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171645</td>\n",
       "      <td>-1.148866</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>1.954923</td>\n",
       "      <td>-0.122130</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>-0.839556</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887234</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>71.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.911585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cameroon</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.202437</td>\n",
       "      <td>-0.530246</td>\n",
       "      <td>69.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.284196</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>-0.839556</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887234</td>\n",
       "      <td>-0.284196</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>Japan</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.581113</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.265963</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.461168</td>\n",
       "      <td>-0.994211</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.954923</td>\n",
       "      <td>-0.122130</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.706995</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.954923</td>\n",
       "      <td>-0.122130</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bosnia-Herzegovina</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.287454</td>\n",
       "      <td>-1.458176</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.265963</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>England</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.634881</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.915742</td>\n",
       "      <td>0.298964</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.623393</td>\n",
       "      <td>-0.994211</td>\n",
       "      <td>67.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.513849</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Germany</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.692785</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>-1.145395</td>\n",
       "      <td>1.141150</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mexico</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.706995</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>71.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.911585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750690</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>70.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.113741</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>-0.628676</td>\n",
       "      <td>1.421878</td>\n",
       "      <td>76.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.156021</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>81.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.284196</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Germany</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.098117</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.519590</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>70.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333871</td>\n",
       "      <td>-0.839556</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>70.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.982308</td>\n",
       "      <td>-0.839556</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>70.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Greece</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.086629</td>\n",
       "      <td>-0.994211</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.226783</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Bosnia-Herzegovina</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.028724</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.341609</td>\n",
       "      <td>-1.245044</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>France</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.117697</td>\n",
       "      <td>0.720057</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Cameroon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750690</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>2.127163</td>\n",
       "      <td>-0.402858</td>\n",
       "      <td>69.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Russia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.156021</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>81.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.169369</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.808594</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.284196</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.519072</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.284196</td>\n",
       "      <td>-0.964316</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Japan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.098117</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>1.265963</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Bosnia-Herzegovina</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.623393</td>\n",
       "      <td>-0.994211</td>\n",
       "      <td>67.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.341609</td>\n",
       "      <td>-1.245044</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.808594</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>72.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.743502</td>\n",
       "      <td>1.141150</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.750690</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.117697</td>\n",
       "      <td>0.720057</td>\n",
       "      <td>71.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.098117</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-1.030569</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.634881</td>\n",
       "      <td>-0.375591</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>-1.385409</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750690</td>\n",
       "      <td>-0.684901</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954234</td>\n",
       "      <td>-0.456436</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Iran</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954234</td>\n",
       "      <td>1.151137</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>66.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Grenada</td>\n",
       "      <td>Panama</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.291590</td>\n",
       "      <td>0.397684</td>\n",
       "      <td>68.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.725270</td>\n",
       "      <td>-1.385409</td>\n",
       "      <td>64.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.954488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>Northern Ireland</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.982308</td>\n",
       "      <td>1.325615</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.456436</td>\n",
       "      <td>0.018235</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Panama</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.218062</td>\n",
       "      <td>-0.994211</td>\n",
       "      <td>66.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.725270</td>\n",
       "      <td>-1.385409</td>\n",
       "      <td>64.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.954488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.982308</td>\n",
       "      <td>3.336131</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>2.586469</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>Honduras</td>\n",
       "      <td>Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.040212</td>\n",
       "      <td>3.645441</td>\n",
       "      <td>70.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>1.610443</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.028724</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>66.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>-1.030569</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>73.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>England</td>\n",
       "      <td>Germany</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.634881</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.973155</td>\n",
       "      <td>1.141150</td>\n",
       "      <td>79.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-0.911585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750690</td>\n",
       "      <td>-0.684901</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954234</td>\n",
       "      <td>2.184576</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>-0.530246</td>\n",
       "      <td>70.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.743502</td>\n",
       "      <td>0.298964</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.098117</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.341609</td>\n",
       "      <td>0.720057</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Japan</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.086629</td>\n",
       "      <td>-0.839556</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.858329</td>\n",
       "      <td>1.421878</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954234</td>\n",
       "      <td>-1.202809</td>\n",
       "      <td>0.860421</td>\n",
       "      <td>78.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866499</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>0.175111</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.040212</td>\n",
       "      <td>1.944235</td>\n",
       "      <td>71.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887234</td>\n",
       "      <td>1.208550</td>\n",
       "      <td>-1.245044</td>\n",
       "      <td>68.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>Greece</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.040212</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.171645</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.806657</td>\n",
       "      <td>-1.385409</td>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.797106</td>\n",
       "      <td>-0.684901</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>2.184576</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>Poland</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>-0.530246</td>\n",
       "      <td>70.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>-0.341609</td>\n",
       "      <td>0.720057</td>\n",
       "      <td>72.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>-0.375591</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>1.093723</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.156021</td>\n",
       "      <td>0.861650</td>\n",
       "      <td>78.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>2.586469</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>67.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.861650</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>0.175111</td>\n",
       "      <td>-0.823951</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>Korea Republic</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.028724</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>66.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>1.897510</td>\n",
       "      <td>0.158599</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>Austria</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754826</td>\n",
       "      <td>-0.220936</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>-0.743502</td>\n",
       "      <td>0.298964</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>Russia</td>\n",
       "      <td>Spain</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>-0.066281</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954234</td>\n",
       "      <td>-0.915742</td>\n",
       "      <td>0.579692</td>\n",
       "      <td>82.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-0.445067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>England</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.634881</td>\n",
       "      <td>0.552340</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>-0.858329</td>\n",
       "      <td>1.421878</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.098117</td>\n",
       "      <td>0.243029</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426867</td>\n",
       "      <td>2.012336</td>\n",
       "      <td>-0.683587</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.487970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>Germany</td>\n",
       "      <td>France</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.924403</td>\n",
       "      <td>1.170960</td>\n",
       "      <td>79.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.887234</td>\n",
       "      <td>-0.054543</td>\n",
       "      <td>0.579692</td>\n",
       "      <td>77.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               home_team           away_team  home_score  away_score  \\\n",
       "0                 Greece      Korea Republic           1           1   \n",
       "1                Nigeria               Ghana           1           0   \n",
       "2               Cameroon         Ivory Coast           1           1   \n",
       "3                Nigeria         Ivory Coast           0           1   \n",
       "4                    USA               Japan           3           2   \n",
       "5             Costa Rica      Korea Republic           1           0   \n",
       "6                 Mexico      Korea Republic           0           1   \n",
       "7     Bosnia-Herzegovina               Japan           2           2   \n",
       "8                England             Uruguay           2           1   \n",
       "9                   Iran          Costa Rica           3           2   \n",
       "10                 Italy             Germany           4           1   \n",
       "11                Mexico               Ghana           1           0   \n",
       "12           Netherlands             Ecuador           1           0   \n",
       "13                Russia              Brazil           0           1   \n",
       "14                 Spain         Ivory Coast           3           2   \n",
       "15               Germany                 USA           4           1   \n",
       "16                 Japan             Ecuador           1           0   \n",
       "17              Colombia             Ecuador           1           1   \n",
       "18             Australia              Greece           1           0   \n",
       "19        Korea Republic  Bosnia-Herzegovina           2           0   \n",
       "20                France              Mexico           1           0   \n",
       "21           Netherlands            Cameroon           1           0   \n",
       "22                 Spain              Russia           0           0   \n",
       "23           Switzerland         Ivory Coast           1           1   \n",
       "24                 Chile         Ivory Coast           1           1   \n",
       "25               Germany               Japan           2           2   \n",
       "26                  Iran  Bosnia-Herzegovina           5           2   \n",
       "27           Switzerland               Italy           1           1   \n",
       "28           Netherlands              Mexico           2           1   \n",
       "29               Germany            Colombia           3           0   \n",
       "...                  ...                 ...         ...         ...   \n",
       "2210         Netherlands              Sweden           2           0   \n",
       "2211            Portugal         Switzerland           2           0   \n",
       "2212              Russia                Iran           1           1   \n",
       "2213             Grenada              Panama           0           5   \n",
       "2214    Northern Ireland         Switzerland           0           1   \n",
       "2215                Iran              Panama           2           1   \n",
       "2216             Algeria             Nigeria           1           1   \n",
       "2217            Honduras           Australia           0           0   \n",
       "2218      Korea Republic            Colombia           2           1   \n",
       "2219             England             Germany           0           0   \n",
       "2220            Portugal        Saudi Arabia           3           0   \n",
       "2221              Poland             Uruguay           0           0   \n",
       "2222             Belgium              Mexico           3           3   \n",
       "2223               Japan              Brazil           1           3   \n",
       "2224              Russia           Argentina           0           1   \n",
       "2225               Spain          Costa Rica           5           0   \n",
       "2226               Ghana               Egypt           1           1   \n",
       "2227              Greece             Croatia           0           0   \n",
       "2228               Italy              Sweden           0           0   \n",
       "2229            Bulgaria        Saudi Arabia           1           0   \n",
       "2230              Poland              Mexico           0           1   \n",
       "2231             Ireland             Denmark           1           5   \n",
       "2232           Argentina             Nigeria           2           4   \n",
       "2233             Hungary          Costa Rica           1           0   \n",
       "2234      Korea Republic              Serbia           1           1   \n",
       "2235             Austria             Uruguay           2           1   \n",
       "2236              Russia               Spain           3           3   \n",
       "2237             England              Brazil           0           0   \n",
       "2238             Belgium               Japan           1           0   \n",
       "2239             Germany              France           2           2   \n",
       "\n",
       "          HTRF      THFP  PHPAR  PHSPAR  PHPSAR  PHDAR    ...        PHAAR  \\\n",
       "0    -0.171645 -1.148866   73.0    66.0    79.0   62.0    ...     0.493867   \n",
       "1     0.696922 -0.839556   70.0    64.0    80.0   61.0    ...    -0.887234   \n",
       "2     2.202437 -0.530246   69.0    64.0    81.0   63.0    ...    -0.426867   \n",
       "3     0.696922 -0.839556   70.0    64.0    80.0   61.0    ...    -0.887234   \n",
       "4     0.581113 -0.066281   70.0    66.0    80.0   62.0    ...     0.033500   \n",
       "5    -0.461168 -0.994211   66.0    60.0    76.0   57.0    ...     0.033500   \n",
       "6     0.175781  0.706995   71.0    64.0    75.0   62.0    ...     0.033500   \n",
       "7    -0.287454 -1.458176   73.0    66.0    79.0   61.0    ...     0.033500   \n",
       "8    -0.634881  0.552340   75.0    68.0    81.0   64.0    ...    -0.426867   \n",
       "9     1.623393 -0.994211   67.0    60.0    75.0   58.0    ...     0.493867   \n",
       "10   -0.692785  1.170960   76.0    68.0    81.0   66.0    ...     0.033500   \n",
       "11    0.175781  0.706995   71.0    64.0    75.0   62.0    ...     0.033500   \n",
       "12   -0.750690 -0.066281   74.0    68.0    80.0   63.0    ...    -0.426867   \n",
       "13   -0.113741 -0.066281   71.0    64.0    76.0   62.0    ...     0.033500   \n",
       "14   -1.156021  0.552340   81.0    71.0    79.0   67.0    ...     0.493867   \n",
       "15   -1.098117  1.170960   76.0    69.0    81.0   67.0    ...    -0.426867   \n",
       "16    1.333871 -0.839556   72.0    66.0    74.0   63.0    ...     0.033500   \n",
       "17   -0.982308 -0.839556   73.0    67.0    80.0   63.0    ...     0.033500   \n",
       "18    2.086629 -0.994211   71.0    64.0    78.0   62.0    ...    -0.426867   \n",
       "19    2.028724 -0.220936   72.0    67.0    78.0   62.0    ...    -0.426867   \n",
       "20    0.002068  0.552340   76.0    69.0    80.0   68.0    ...    -0.426867   \n",
       "21   -0.750690 -0.066281   74.0    68.0    80.0   63.0    ...    -0.426867   \n",
       "22   -1.156021  0.552340   81.0    71.0    79.0   67.0    ...     0.493867   \n",
       "23   -0.808594 -0.066281   72.0    66.0    80.0   65.0    ...    -0.426867   \n",
       "24   -0.519072 -0.220936   73.0    68.0    76.0   64.0    ...     0.493867   \n",
       "25   -1.098117  1.170960   76.0    69.0    81.0   67.0    ...    -0.426867   \n",
       "26    1.623393 -0.994211   67.0    60.0    75.0   58.0    ...     0.493867   \n",
       "27   -0.808594 -0.066281   72.0    66.0    80.0   65.0    ...    -0.426867   \n",
       "28   -0.750690 -0.066281   74.0    68.0    80.0   63.0    ...    -0.426867   \n",
       "29   -1.098117  1.170960   76.0    69.0    81.0   67.0    ...    -0.426867   \n",
       "...        ...       ...    ...     ...     ...    ...    ...          ...   \n",
       "2210 -0.634881 -0.375591   74.0    68.0    80.0   63.0    ...    -0.426867   \n",
       "2211 -0.750690 -0.684901   74.0    67.0    78.0   67.0    ...     0.954234   \n",
       "2212  0.349495 -0.066281   73.0    64.0    78.0   66.0    ...     0.954234   \n",
       "2213  0.291590  0.397684   68.0    62.0    76.0   62.0    ...     0.033500   \n",
       "2214 -0.982308  1.325615   74.0    66.0    79.0   65.0    ...     0.493867   \n",
       "2215  1.218062 -0.994211   66.0    59.0    74.0   60.0    ...     0.033500   \n",
       "2216 -0.982308  3.336131   70.0    62.0    78.0   62.0    ...    -0.426867   \n",
       "2217 -1.040212  3.645441   70.0    62.0    78.0   60.0    ...     0.493867   \n",
       "2218  2.028724 -0.220936   66.0    57.0    76.0   64.0    ...     0.033500   \n",
       "2219 -0.634881  0.552340   73.0    66.0    77.0   68.0    ...    -0.426867   \n",
       "2220 -0.750690 -0.684901   74.0    67.0    78.0   67.0    ...     0.954234   \n",
       "2221  0.349495 -0.530246   70.0    63.0    78.0   64.0    ...     0.493867   \n",
       "2222 -1.098117  0.243029   75.0    67.0    83.0   66.0    ...    -0.426867   \n",
       "2223  2.086629 -0.839556   73.0    66.0    75.0   67.0    ...     0.493867   \n",
       "2224  0.349495 -0.066281   73.0    64.0    78.0   66.0    ...     0.954234   \n",
       "2225 -0.866499  0.552340   82.0    69.0    78.0   67.0    ...    -0.426867   \n",
       "2226 -1.040212  1.944235   71.0    66.0    80.0   63.0    ...    -0.887234   \n",
       "2227 -1.040212  1.170960   73.0    66.0    79.0   62.0    ...     0.493867   \n",
       "2228 -0.171645 -0.220936   76.0    68.0    81.0   66.0    ...     0.033500   \n",
       "2229  1.797106 -0.684901   68.0    61.0    77.0   65.0    ...     0.033500   \n",
       "2230  0.349495 -0.530246   70.0    63.0    78.0   64.0    ...     0.493867   \n",
       "2231  0.696922 -0.375591   72.0    65.0    78.0   65.0    ...     0.493867   \n",
       "2232 -1.156021  0.861650   78.0    69.0    80.0   68.0    ...     0.493867   \n",
       "2233  0.175781  0.861650   69.0    60.0    76.0   62.0    ...     0.493867   \n",
       "2234  2.028724 -0.220936   66.0    57.0    76.0   64.0    ...     0.033500   \n",
       "2235  0.754826 -0.220936   69.0    60.0    75.0   64.0    ...     0.033500   \n",
       "2236  0.349495 -0.066281   73.0    64.0    78.0   66.0    ...     0.954234   \n",
       "2237 -0.634881  0.552340   73.0    66.0    77.0   68.0    ...    -0.426867   \n",
       "2238 -1.098117  0.243029   75.0    67.0    83.0   66.0    ...    -0.426867   \n",
       "2239 -0.924403  1.170960   79.0    71.0    79.0   65.0    ...    -0.887234   \n",
       "\n",
       "          ATRF      TAFP  PAPAR  PASPAR  PAPSAR  PADAR  PATSA  PADBAR  \\\n",
       "0     1.954923 -0.122130   72.0    67.0    78.0   62.0   77.0    73.0   \n",
       "1     0.060284 -0.964316   71.0    66.0    80.0   63.0   81.0    74.0   \n",
       "2    -0.284196 -0.964316   72.0    65.0    80.0   62.0   80.0    73.0   \n",
       "3    -0.284196 -0.964316   72.0    65.0    80.0   62.0   80.0    73.0   \n",
       "4     1.265963 -0.683587   72.0    66.0    74.0   63.0   73.0    72.0   \n",
       "5     1.954923 -0.122130   72.0    67.0    78.0   62.0   77.0    73.0   \n",
       "6     1.954923 -0.122130   72.0    67.0    78.0   62.0   77.0    73.0   \n",
       "7     1.265963 -0.683587   72.0    66.0    74.0   63.0   73.0    72.0   \n",
       "8    -0.915742  0.298964   72.0    66.0    80.0   65.0   77.0    74.0   \n",
       "9    -0.513849 -0.823951   66.0    60.0    76.0   57.0   74.0    67.0   \n",
       "10   -1.145395  1.141150   76.0    69.0    81.0   67.0   77.0    76.0   \n",
       "11    0.060284 -0.964316   71.0    66.0    80.0   63.0   81.0    74.0   \n",
       "12    0.002871 -0.964316   70.0    65.0    77.0   57.0   80.0    75.0   \n",
       "13   -0.628676  1.421878   76.0    70.0    80.0   65.0   79.0    79.0   \n",
       "14   -0.284196 -0.964316   72.0    65.0    80.0   62.0   80.0    73.0   \n",
       "15    0.519590  0.018235   70.0    66.0    80.0   62.0   77.0    72.0   \n",
       "16    0.002871 -0.964316   70.0    65.0    77.0   57.0   80.0    75.0   \n",
       "17    0.002871 -0.964316   70.0    65.0    77.0   57.0   80.0    75.0   \n",
       "18   -0.226783 -0.964316   73.0    66.0    79.0   62.0   76.0    74.0   \n",
       "19   -0.341609 -1.245044   73.0    66.0    79.0   61.0   77.0    75.0   \n",
       "20    0.117697  0.720057   71.0    64.0    75.0   62.0   76.0    72.0   \n",
       "21    2.127163 -0.402858   69.0    64.0    81.0   63.0   81.0    74.0   \n",
       "22   -0.169369  0.018235   71.0    64.0    76.0   62.0   77.0    75.0   \n",
       "23   -0.284196 -0.964316   72.0    65.0    80.0   62.0   80.0    73.0   \n",
       "24   -0.284196 -0.964316   72.0    65.0    80.0   62.0   80.0    73.0   \n",
       "25    1.265963 -0.683587   72.0    66.0    74.0   63.0   73.0    72.0   \n",
       "26   -0.341609 -1.245044   73.0    66.0    79.0   61.0   77.0    75.0   \n",
       "27   -0.743502  1.141150   76.0    68.0    81.0   66.0   77.0    75.0   \n",
       "28    0.117697  0.720057   71.0    64.0    75.0   62.0   76.0    72.0   \n",
       "29   -1.030569 -0.683587   73.0    67.0    80.0   63.0   79.0    75.0   \n",
       "...        ...       ...    ...     ...     ...    ...    ...     ...   \n",
       "2210  0.806657 -1.385409   70.0    64.0    77.0   64.0   71.0    67.0   \n",
       "2211 -0.456436  0.018235   73.0    66.0    80.0   69.0   75.0    71.0   \n",
       "2212  1.151137 -0.823951   66.0    59.0    74.0   60.0   73.0    65.0   \n",
       "2213  1.725270 -1.385409   64.0    57.0    74.0   60.0   73.0    63.0   \n",
       "2214 -0.456436  0.018235   73.0    66.0    80.0   69.0   75.0    71.0   \n",
       "2215  1.725270 -1.385409   64.0    57.0    74.0   60.0   73.0    63.0   \n",
       "2216  2.586469 -0.683587   67.0    58.0    79.0   62.0   77.0    66.0   \n",
       "2217  1.610443 -0.683587   69.0    63.0    77.0   66.0   74.0    68.0   \n",
       "2218 -1.030569 -0.683587   73.0    67.0    79.0   63.0   78.0    74.0   \n",
       "2219 -0.973155  1.141150   79.0    71.0    79.0   65.0   78.0    78.0   \n",
       "2220  2.184576 -0.823951   65.0    56.0    73.0   62.0   76.0    65.0   \n",
       "2221 -0.743502  0.298964   73.0    66.0    78.0   68.0   76.0    74.0   \n",
       "2222 -0.341609  0.720057   72.0    62.0    75.0   65.0   77.0    71.0   \n",
       "2223 -0.858329  1.421878   76.0    66.0    77.0   68.0   80.0    77.0   \n",
       "2224 -1.202809  0.860421   78.0    69.0    80.0   68.0   77.0    77.0   \n",
       "2225  0.175111 -0.823951   68.0    60.0    74.0   65.0   75.0    67.0   \n",
       "2226  1.208550 -1.245044   68.0    64.0    78.0   67.0   76.0    69.0   \n",
       "2227  0.060284 -0.823951   74.0    66.0    77.0   65.0   74.0    71.0   \n",
       "2228  0.806657 -1.385409   70.0    64.0    77.0   64.0   71.0    67.0   \n",
       "2229  2.184576 -0.823951   65.0    56.0    73.0   62.0   76.0    65.0   \n",
       "2230 -0.341609  0.720057   72.0    62.0    75.0   65.0   77.0    71.0   \n",
       "2231  1.093723 -0.683587   73.0    64.0    78.0   65.0   73.0    69.0   \n",
       "2232  2.586469 -0.683587   67.0    58.0    79.0   62.0   77.0    66.0   \n",
       "2233  0.175111 -0.823951   68.0    60.0    74.0   65.0   75.0    67.0   \n",
       "2234  1.897510  0.158599   72.0    64.0    80.0   65.0   74.0    71.0   \n",
       "2235 -0.743502  0.298964   73.0    66.0    78.0   68.0   76.0    74.0   \n",
       "2236 -0.915742  0.579692   82.0    69.0    78.0   67.0   76.0    79.0   \n",
       "2237 -0.858329  1.421878   76.0    66.0    77.0   68.0   80.0    77.0   \n",
       "2238  2.012336 -0.683587   73.0    66.0    75.0   67.0   75.0    73.0   \n",
       "2239 -0.054543  0.579692   77.0    66.0    82.0   72.0   79.0    73.0   \n",
       "\n",
       "         PAAAR  \n",
       "0    -0.445067  \n",
       "1    -0.911585  \n",
       "2     0.021452  \n",
       "3     0.021452  \n",
       "4     0.021452  \n",
       "5    -0.445067  \n",
       "6    -0.445067  \n",
       "7     0.021452  \n",
       "8     0.487970  \n",
       "9     0.021452  \n",
       "10   -0.445067  \n",
       "11   -0.911585  \n",
       "12    0.021452  \n",
       "13    0.487970  \n",
       "14    0.021452  \n",
       "15    0.021452  \n",
       "16    0.021452  \n",
       "17    0.021452  \n",
       "18    0.487970  \n",
       "19    0.021452  \n",
       "20    0.021452  \n",
       "21   -0.445067  \n",
       "22    0.021452  \n",
       "23    0.021452  \n",
       "24    0.021452  \n",
       "25    0.021452  \n",
       "26    0.021452  \n",
       "27    0.021452  \n",
       "28    0.021452  \n",
       "29    0.021452  \n",
       "...        ...  \n",
       "2210  0.487970  \n",
       "2211 -0.445067  \n",
       "2212  0.021452  \n",
       "2213  0.954488  \n",
       "2214 -0.445067  \n",
       "2215  0.954488  \n",
       "2216 -0.445067  \n",
       "2217  0.021452  \n",
       "2218  0.021452  \n",
       "2219 -0.911585  \n",
       "2220  0.021452  \n",
       "2221  0.021452  \n",
       "2222  0.021452  \n",
       "2223  0.021452  \n",
       "2224  0.487970  \n",
       "2225  0.487970  \n",
       "2226 -0.445067  \n",
       "2227  0.021452  \n",
       "2228  0.487970  \n",
       "2229  0.021452  \n",
       "2230  0.021452  \n",
       "2231  0.487970  \n",
       "2232 -0.445067  \n",
       "2233  0.487970  \n",
       "2234  0.021452  \n",
       "2235  0.021452  \n",
       "2236 -0.445067  \n",
       "2237  0.021452  \n",
       "2238  0.487970  \n",
       "2239  0.021452  \n",
       "\n",
       "[2240 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_size = independent_data_train.values.shape[0]\n",
    "#data train\n",
    "independent_data_train['THFP'] = scaler.fit_transform(independent_data_train['THFP'].values.reshape([train_size,-1]))\n",
    "independent_data_train['HTRF'] = scaler.fit_transform(independent_data_train['HTRF'].values.reshape([train_size,-1]))\n",
    "independent_data_train['TAFP'] = scaler.fit_transform(independent_data_train['TAFP'].values.reshape([train_size,-1]))\n",
    "independent_data_train['ATRF'] = scaler.fit_transform(independent_data_train['ATRF'].values.reshape([train_size,-1]))\n",
    "independent_data_train['PHAAR'] = scaler.fit_transform(independent_data_train['PHAAR'].values.reshape([train_size,-1]))\n",
    "independent_data_train['PAAAR'] = scaler.fit_transform(independent_data_train['PAAAR'].values.reshape([train_size,-1]))\n",
    "\n",
    "independent_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_y=preprocessingData_onehotencoder(dependent_data_train)\n",
    "data_x=independent_data_train.iloc[:,[4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_train_test_data(data_x, data_y):\n",
    "    train_size = 0.8\n",
    "    train_cnt = floor(data_x.shape[0] * train_size)\n",
    "\n",
    "    train_x, test_x = data_x[0:train_cnt], data_x[train_cnt:]\n",
    "    train_y, test_y = data_y[0:train_cnt], data_y[train_cnt:]\n",
    "\n",
    "    train_y2 = np.argmax(train_y, axis=1)\n",
    "    test_y2 = np.argmax(test_y, axis=1)\n",
    "\n",
    "    return train_x, test_x, train_y2, test_y2, train_cnt\n",
    "\n",
    "\n",
    "def neural_network(x_, w1, w2, w3, wout, b1, b2, b3, bout):\n",
    "    l1 = tf.sigmoid(tf.matmul(x_, w1) + b1)\n",
    "    # l1 = tf.nn.dropout(l1, keep_prob)\n",
    "\n",
    "    l2 = tf.sigmoid(tf.matmul(l1, w2) + b2)\n",
    "    # l2 = tf.nn.dropout(l2, keep_prob)\n",
    "\n",
    "    l3 = tf.sigmoid(tf.matmul(l2, w3) + b3)\n",
    "    # l3 = tf.nn.dropout(l3, keep_prob)\n",
    "\n",
    "    l_out = tf.matmul(l3, wout) + bout\n",
    "\n",
    "    return l_out\n",
    "\n",
    "\n",
    "def build_bayesian_network(x_, y_, in_size, out_size):\n",
    "    n_nodes_hl1 = 100\n",
    "    n_nodes_hl2 = 100\n",
    "    n_nodes_hl3 = 100\n",
    "\n",
    "    w_h1 = Normal(loc=tf.zeros([in_size, n_nodes_hl1]),\n",
    "                  scale=tf.ones([in_size, n_nodes_hl1]))\n",
    "    w_h2 = Normal(loc=tf.zeros([n_nodes_hl1, n_nodes_hl2]),\n",
    "                  scale=tf.ones([n_nodes_hl1, n_nodes_hl2]))\n",
    "    w_h3 = Normal(loc=tf.zeros([n_nodes_hl2, n_nodes_hl3]),\n",
    "                  scale=tf.ones([n_nodes_hl2, n_nodes_hl3]))\n",
    "    w_hout = Normal(loc=tf.zeros([n_nodes_hl3, out_size]),\n",
    "                    scale=tf.ones([n_nodes_hl3, out_size]))\n",
    "    b_h1 = Normal(loc=tf.zeros([n_nodes_hl1]),\n",
    "                  scale=tf.ones([n_nodes_hl1]))\n",
    "    b_h2 = Normal(loc=tf.zeros([n_nodes_hl2]),\n",
    "                  scale=tf.ones([n_nodes_hl2]))\n",
    "    b_h3 = Normal(loc=tf.zeros([n_nodes_hl3]),\n",
    "                  scale=tf.ones([n_nodes_hl3]))\n",
    "    b_hout = Normal(loc=tf.zeros([out_size]),\n",
    "                    scale=tf.ones([out_size]))\n",
    "\n",
    "    y_pre = Categorical(neural_network(x_, w_h1, w_h2, w_h3, w_hout, b_h1, b_h2, b_h3, b_hout))\n",
    "\n",
    "    qw_h1 = Normal(loc=tf.Variable(tf.random_normal([in_size, n_nodes_hl1])),\n",
    "                   scale=tf.Variable(tf.random_normal([in_size, n_nodes_hl1])))\n",
    "    qw_h2 = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                   scale=tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])))\n",
    "    qw_h3 = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                   scale=tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])))\n",
    "    qw_hout = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl3, out_size])),\n",
    "                     scale=tf.Variable(tf.random_normal([n_nodes_hl3, out_size])))\n",
    "    qb_h1 = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl1])),\n",
    "                   scale=tf.Variable(tf.random_normal([n_nodes_hl1])))\n",
    "    qb_h2 = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl2])),\n",
    "                   scale=tf.Variable(tf.random_normal([n_nodes_hl2])))\n",
    "    qb_h3 = Normal(loc=tf.Variable(tf.random_normal([n_nodes_hl3])),\n",
    "                   scale=tf.Variable(tf.random_normal([n_nodes_hl3])))\n",
    "    qb_hout = Normal(loc=tf.Variable(tf.random_normal([out_size])),\n",
    "                     scale=tf.Variable(tf.random_normal([out_size])))\n",
    "\n",
    "    y = Categorical(neural_network(x_, qw_h1, qw_h2, qw_h3, qw_hout, qb_h1, qb_h2, qb_h3, qb_hout))\n",
    "\n",
    "    inference = ed.KLqp({w_h1: qw_h1, b_h1: qb_h1,\n",
    "                         w_h2: qw_h2, b_h2: qb_h2,\n",
    "                         w_h3: qw_h3, b_h3: qb_h3,\n",
    "                         w_hout: qw_hout, b_hout: qb_hout}, data={y_pre: y_})\n",
    "    inference.initialize()\n",
    "\n",
    "    return inference, y_pre, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=[]\n",
    "accuracy_val=[]\n",
    "accuracy_train=[]\n",
    "error_training=[]\n",
    "error_vald=[]\n",
    "\n",
    "tr_x=[]\n",
    "tr_y=[]\n",
    "val_x=[]\n",
    "val_y=[]\n",
    "y_samp=[]\n",
    "from sklearn import metrics  \n",
    "epochs=[10,30,50,70,90]\n",
    "def train_bayesian_network(data_x, data_y, in_size, out_size):\n",
    "    for a in range(len(epochs)):\n",
    "        training_epochs = epochs[a]\n",
    "        batch_size = 1000\n",
    "        print(training_epochs)\n",
    "        x_ = tf.placeholder(tf.float32, shape=(None, in_size))\n",
    "        y_ = tf.placeholder(tf.int32)\n",
    "\n",
    "        train_x, test_x, train_y2, test_y2, train_cnt = prepare_train_test_data(data_x, data_y)\n",
    "        tr_x.append(train_x)\n",
    "        tr_y.append(train_y2)\n",
    "        val_x.append(test_x)\n",
    "        val_y.append(test_y2)\n",
    "        inference, y_pre, y = build_bayesian_network(x_, y_, in_size, out_size)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with sess:\n",
    "            samples_num = 100\n",
    "            for epoch in tqdm(range(training_epochs), file=sys.stdout):\n",
    "                perm = np.random.permutation(train_cnt)\n",
    "                for i in range(0, train_cnt, batch_size):\n",
    "                    batch_x = train_x[perm[i:i + batch_size]]\n",
    "                    batch_y = train_y2[perm[i:i + batch_size]]\n",
    "                    inference.update(feed_dict={x_: batch_x, y_: batch_y})\n",
    "\n",
    "                #train\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: train_x})   \n",
    "                acc = (np.round(y_samples.sum(axis=0) / samples_num) == train_y2).mean()\n",
    "                predic_train=np.round((y_samples.sum(axis=0) / samples_num) == train_y2)\n",
    "                accuracy_train.append(acc)\n",
    "                loss_train=metrics.mean_absolute_error(train_y2, predic_train)\n",
    "                error_training.append(loss_train)\n",
    "\n",
    "\n",
    "                #validation\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: test_x})\n",
    "                tets_acc = (np.round(y_samples.sum(axis=0) / samples_num) == test_y2).mean()            \n",
    "                predic_val=np.round((y_samples.sum(axis=0) / samples_num) == test_y2)            \n",
    "                pred.append(predic_val)\n",
    "                accuracy_val.append(tets_acc)\n",
    "                loss_val=metrics.mean_absolute_error(test_y2, predic_val)\n",
    "                error_vald.append(loss_val)\n",
    "                print(\"epoch: {0};\\naccuracy: {1};\\nvalidation accuracy: {2}\"\n",
    "                                .format(epoch,acc,tets_acc))\n",
    " \n",
    "#           tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(training_epochs+1, acc, tets_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]epoch: 0;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.37723214285714285\n",
      " 10%|████████▎                                                                          | 1/10 [00:00<00:05,  1.60it/s]epoch: 1;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:00<00:03,  2.33it/s]epoch: 2;\n",
      "accuracy: 0.24665178571428573;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:01<00:02,  2.49it/s]epoch: 3;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:01<00:02,  2.75it/s]epoch: 4;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:01<00:01,  2.96it/s]epoch: 5;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:01<00:01,  3.12it/s]epoch: 6;\n",
      "accuracy: 0.2611607142857143;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:02<00:00,  3.25it/s]epoch: 7;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:02<00:00,  3.32it/s]epoch: 8;\n",
      "accuracy: 0.23660714285714285;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:02<00:00,  3.37it/s]epoch: 9;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.42it/s]\n",
      "30\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]epoch: 0;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  3%|██▊                                                                                | 1/30 [00:00<00:12,  2.37it/s]epoch: 1;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2767857142857143\n",
      "  7%|█████▌                                                                             | 2/30 [00:00<00:10,  2.56it/s]epoch: 2;\n",
      "accuracy: 0.23828125;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 10%|████████▎                                                                          | 3/30 [00:01<00:10,  2.67it/s]epoch: 3;\n",
      "accuracy: 0.49497767857142855;\n",
      "validation accuracy: 0.25\n",
      " 13%|███████████                                                                        | 4/30 [00:01<00:09,  2.69it/s]epoch: 4;\n",
      "accuracy: 0.23660714285714285;\n",
      "validation accuracy: 0.3549107142857143\n",
      " 17%|█████████████▊                                                                     | 5/30 [00:01<00:09,  2.71it/s]epoch: 5;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 20%|████████████████▌                                                                  | 6/30 [00:02<00:08,  2.72it/s]epoch: 6;\n",
      "accuracy: 0.26060267857142855;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 23%|███████████████████▎                                                               | 7/30 [00:02<00:08,  2.72it/s]epoch: 7;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.359375\n",
      " 27%|██████████████████████▏                                                            | 8/30 [00:02<00:08,  2.71it/s]epoch: 8;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 30%|████████████████████████▉                                                          | 9/30 [00:03<00:07,  2.70it/s]epoch: 9;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 33%|███████████████████████████▎                                                      | 10/30 [00:03<00:07,  2.70it/s]epoch: 10;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.26785714285714285\n",
      " 37%|██████████████████████████████                                                    | 11/30 [00:04<00:07,  2.70it/s]epoch: 11;\n",
      "accuracy: 0.26395089285714285;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 40%|████████████████████████████████▊                                                 | 12/30 [00:04<00:06,  2.69it/s]epoch: 12;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.3638392857142857\n",
      " 43%|███████████████████████████████████▌                                              | 13/30 [00:04<00:06,  2.68it/s]epoch: 13;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 47%|██████████████████████████████████████▎                                           | 14/30 [00:05<00:05,  2.67it/s]epoch: 14;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.359375\n",
      " 50%|█████████████████████████████████████████                                         | 15/30 [00:05<00:05,  2.67it/s]epoch: 15;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 53%|███████████████████████████████████████████▋                                      | 16/30 [00:06<00:05,  2.67it/s]epoch: 16;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 57%|██████████████████████████████████████████████▍                                   | 17/30 [00:06<00:04,  2.66it/s]epoch: 17;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 60%|█████████████████████████████████████████████████▏                                | 18/30 [00:06<00:04,  2.65it/s]epoch: 18;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.24776785714285715\n",
      " 63%|███████████████████████████████████████████████████▉                              | 19/30 [00:07<00:04,  2.66it/s]epoch: 19;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 20/30 [00:07<00:03,  2.66it/s]epoch: 20;\n",
      "accuracy: 0.30859375;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 21/30 [00:07<00:03,  2.66it/s]epoch: 21;\n",
      "accuracy: 0.23660714285714285;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 73%|████████████████████████████████████████████████████████████▏                     | 22/30 [00:08<00:03,  2.65it/s]epoch: 22;\n",
      "accuracy: 0.2611607142857143;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 77%|██████████████████████████████████████████████████████████████▊                   | 23/30 [00:08<00:02,  2.60it/s]epoch: 23;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 24/30 [00:09<00:02,  2.60it/s]epoch: 24;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 25/30 [00:09<00:01,  2.60it/s]epoch: 25;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.296875\n",
      " 87%|███████████████████████████████████████████████████████████████████████           | 26/30 [00:10<00:01,  2.59it/s]epoch: 26;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 27/30 [00:10<00:01,  2.59it/s]epoch: 27;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▌     | 28/30 [00:10<00:00,  2.58it/s]epoch: 28;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▎  | 29/30 [00:11<00:00,  2.58it/s]epoch: 29;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.58it/s]\n",
      "50\n",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]epoch: 0;\n",
      "accuracy: 0.2583705357142857;\n",
      "validation accuracy: 0.31919642857142855\n",
      "  2%|█▋                                                                                 | 1/50 [00:00<00:28,  1.73it/s]epoch: 1;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.30580357142857145\n",
      "  4%|███▎                                                                               | 2/50 [00:01<00:25,  1.86it/s]epoch: 2;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  6%|████▉                                                                              | 3/50 [00:01<00:24,  1.88it/s]epoch: 3;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.359375\n",
      "  8%|██████▋                                                                            | 4/50 [00:02<00:24,  1.90it/s]epoch: 4;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 10%|████████▎                                                                          | 5/50 [00:02<00:23,  1.90it/s]epoch: 5;\n",
      "accuracy: 0.25613839285714285;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 12%|█████████▉                                                                         | 6/50 [00:03<00:23,  1.88it/s]epoch: 6;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 14%|███████████▌                                                                       | 7/50 [00:03<00:22,  1.87it/s]epoch: 7;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 16%|█████████████▎                                                                     | 8/50 [00:04<00:22,  1.86it/s]epoch: 8;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 18%|██████████████▉                                                                    | 9/50 [00:04<00:22,  1.86it/s]epoch: 9;\n",
      "accuracy: 0.23828125;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 20%|████████████████▍                                                                 | 10/50 [00:05<00:21,  1.87it/s]epoch: 10;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 22%|██████████████████                                                                | 11/50 [00:05<00:20,  1.86it/s]epoch: 11;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 24%|███████████████████▋                                                              | 12/50 [00:06<00:20,  1.86it/s]epoch: 12;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.30357142857142855\n",
      " 26%|█████████████████████▎                                                            | 13/50 [00:07<00:20,  1.85it/s]epoch: 13;\n",
      "accuracy: 0.48214285714285715;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 28%|██████████████████████▉                                                           | 14/50 [00:07<00:19,  1.85it/s]epoch: 14;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 30%|████████████████████████▌                                                         | 15/50 [00:08<00:18,  1.84it/s]epoch: 15;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 32%|██████████████████████████▏                                                       | 16/50 [00:08<00:18,  1.85it/s]epoch: 16;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 34%|███████████████████████████▉                                                      | 17/50 [00:09<00:17,  1.85it/s]epoch: 17;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.359375\n",
      " 36%|█████████████████████████████▌                                                    | 18/50 [00:09<00:17,  1.85it/s]epoch: 18;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 38%|███████████████████████████████▏                                                  | 19/50 [00:10<00:16,  1.85it/s]epoch: 19;\n",
      "accuracy: 0.2622767857142857;\n",
      "validation accuracy: 0.3236607142857143\n",
      " 40%|████████████████████████████████▊                                                 | 20/50 [00:10<00:16,  1.84it/s]epoch: 20;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 42%|██████████████████████████████████▍                                               | 21/50 [00:11<00:15,  1.84it/s]epoch: 21;\n",
      "accuracy: 0.5022321428571429;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 44%|████████████████████████████████████                                              | 22/50 [00:11<00:15,  1.84it/s]epoch: 22;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 46%|█████████████████████████████████████▋                                            | 23/50 [00:12<00:14,  1.84it/s]epoch: 23;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2767857142857143\n",
      " 48%|███████████████████████████████████████▎                                          | 24/50 [00:13<00:14,  1.84it/s]epoch: 24;\n",
      "accuracy: 0.48716517857142855;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 50%|█████████████████████████████████████████                                         | 25/50 [00:13<00:13,  1.83it/s]epoch: 25;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.359375\n",
      " 52%|██████████████████████████████████████████▋                                       | 26/50 [00:14<00:13,  1.83it/s]epoch: 26;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.25892857142857145\n",
      " 54%|████████████████████████████████████████████▎                                     | 27/50 [00:14<00:12,  1.83it/s]epoch: 27;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 56%|█████████████████████████████████████████████▉                                    | 28/50 [00:15<00:12,  1.82it/s]epoch: 28;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 58%|███████████████████████████████████████████████▌                                  | 29/50 [00:15<00:11,  1.82it/s]epoch: 29;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 60%|█████████████████████████████████████████████████▏                                | 30/50 [00:16<00:10,  1.82it/s]epoch: 30;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 62%|██████████████████████████████████████████████████▊                               | 31/50 [00:17<00:10,  1.82it/s]epoch: 31;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.25892857142857145\n",
      " 64%|████████████████████████████████████████████████████▍                             | 32/50 [00:17<00:09,  1.82it/s]epoch: 32;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 66%|██████████████████████████████████████████████████████                            | 33/50 [00:18<00:09,  1.81it/s]epoch: 33;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 68%|███████████████████████████████████████████████████████▊                          | 34/50 [00:18<00:08,  1.81it/s]epoch: 34;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 35/50 [00:19<00:08,  1.81it/s]epoch: 35;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 72%|███████████████████████████████████████████████████████████                       | 36/50 [00:19<00:07,  1.81it/s]epoch: 36;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 74%|████████████████████████████████████████████████████████████▋                     | 37/50 [00:20<00:07,  1.81it/s]epoch: 37;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 76%|██████████████████████████████████████████████████████████████▎                   | 38/50 [00:21<00:06,  1.80it/s]epoch: 38;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 78%|███████████████████████████████████████████████████████████████▉                  | 39/50 [00:21<00:06,  1.80it/s]epoch: 39;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.3549107142857143\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 40/50 [00:22<00:05,  1.80it/s]epoch: 40;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████████████████████████████████████▏              | 41/50 [00:22<00:05,  1.80it/s]epoch: 41;\n",
      "accuracy: 0.23660714285714285;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 84%|████████████████████████████████████████████████████████████████████▉             | 42/50 [00:23<00:04,  1.79it/s]epoch: 42;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 43/50 [00:24<00:03,  1.79it/s]epoch: 43;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 88%|████████████████████████████████████████████████████████████████████████▏         | 44/50 [00:24<00:03,  1.78it/s]epoch: 44;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 45/50 [00:25<00:02,  1.78it/s]epoch: 45;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▍      | 46/50 [00:25<00:02,  1.78it/s]epoch: 46;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████     | 47/50 [00:26<00:01,  1.77it/s]epoch: 47;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▋   | 48/50 [00:27<00:01,  1.77it/s]epoch: 48;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 49/50 [00:27<00:00,  1.77it/s]epoch: 49;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:28<00:00,  1.77it/s]\n",
      "70\n",
      "  0%|                                                                                           | 0/70 [00:00<?, ?it/s]epoch: 0;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  1%|█▏                                                                                 | 1/70 [00:00<00:54,  1.25it/s]epoch: 1;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      "  3%|██▎                                                                                | 2/70 [00:01<00:51,  1.33it/s]epoch: 2;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.3549107142857143\n",
      "  4%|███▌                                                                               | 3/70 [00:02<00:49,  1.36it/s]epoch: 3;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  6%|████▋                                                                              | 4/70 [00:02<00:48,  1.37it/s]epoch: 4;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.32142857142857145\n",
      "  7%|█████▉                                                                             | 5/70 [00:03<00:47,  1.38it/s]epoch: 5;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      "  9%|███████                                                                            | 6/70 [00:04<00:46,  1.39it/s]epoch: 6;\n",
      "accuracy: 0.26060267857142855;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 10%|████████▎                                                                          | 7/70 [00:05<00:45,  1.39it/s]epoch: 7;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 11%|█████████▍                                                                         | 8/70 [00:05<00:44,  1.38it/s]epoch: 8;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 13%|██████████▋                                                                        | 9/70 [00:06<00:43,  1.39it/s]epoch: 9;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 14%|███████████▋                                                                      | 10/70 [00:07<00:43,  1.39it/s]epoch: 10;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 16%|████████████▉                                                                     | 11/70 [00:07<00:42,  1.39it/s]epoch: 11;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 17%|██████████████                                                                    | 12/70 [00:08<00:41,  1.39it/s]epoch: 12;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 19%|███████████████▏                                                                  | 13/70 [00:09<00:41,  1.39it/s]epoch: 13;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 20%|████████████████▍                                                                 | 14/70 [00:10<00:40,  1.39it/s]epoch: 14;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 21%|█████████████████▌                                                                | 15/70 [00:10<00:39,  1.39it/s]epoch: 15;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 23%|██████████████████▋                                                               | 16/70 [00:11<00:38,  1.39it/s]epoch: 16;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 24%|███████████████████▉                                                              | 17/70 [00:12<00:38,  1.39it/s]epoch: 17;\n",
      "accuracy: 0.22209821428571427;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 26%|█████████████████████                                                             | 18/70 [00:13<00:37,  1.38it/s]epoch: 18;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 27%|██████████████████████▎                                                           | 19/70 [00:13<00:36,  1.38it/s]epoch: 19;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 29%|███████████████████████▍                                                          | 20/70 [00:14<00:36,  1.38it/s]epoch: 20;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.3392857142857143\n",
      " 30%|████████████████████████▌                                                         | 21/70 [00:15<00:35,  1.38it/s]epoch: 21;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 31%|█████████████████████████▊                                                        | 22/70 [00:15<00:34,  1.38it/s]epoch: 22;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 33%|██████████████████████████▉                                                       | 23/70 [00:16<00:34,  1.38it/s]epoch: 23;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 34%|████████████████████████████                                                      | 24/70 [00:17<00:33,  1.38it/s]epoch: 24;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 36%|█████████████████████████████▎                                                    | 25/70 [00:18<00:32,  1.37it/s]epoch: 25;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 37%|██████████████████████████████▍                                                   | 26/70 [00:18<00:32,  1.37it/s]epoch: 26;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 39%|███████████████████████████████▋                                                  | 27/70 [00:19<00:31,  1.37it/s]epoch: 27;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 40%|████████████████████████████████▊                                                 | 28/70 [00:20<00:30,  1.37it/s]epoch: 28;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 41%|█████████████████████████████████▉                                                | 29/70 [00:21<00:29,  1.37it/s]epoch: 29;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 43%|███████████████████████████████████▏                                              | 30/70 [00:21<00:29,  1.36it/s]epoch: 30;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 44%|████████████████████████████████████▎                                             | 31/70 [00:22<00:28,  1.36it/s]epoch: 31;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 46%|█████████████████████████████████████▍                                            | 32/70 [00:23<00:27,  1.36it/s]epoch: 32;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 47%|██████████████████████████████████████▋                                           | 33/70 [00:24<00:27,  1.36it/s]epoch: 33;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 49%|███████████████████████████████████████▊                                          | 34/70 [00:25<00:26,  1.36it/s]epoch: 34;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 50%|█████████████████████████████████████████                                         | 35/70 [00:25<00:25,  1.35it/s]epoch: 35;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.27901785714285715\n",
      " 51%|██████████████████████████████████████████▏                                       | 36/70 [00:26<00:25,  1.35it/s]epoch: 36;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35267857142857145\n",
      " 53%|███████████████████████████████████████████▎                                      | 37/70 [00:27<00:24,  1.35it/s]epoch: 37;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 54%|████████████████████████████████████████████▌                                     | 38/70 [00:28<00:23,  1.35it/s]epoch: 38;\n",
      "accuracy: 0.26674107142857145;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 56%|█████████████████████████████████████████████▋                                    | 39/70 [00:29<00:23,  1.34it/s]epoch: 39;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 57%|██████████████████████████████████████████████▊                                   | 40/70 [00:29<00:22,  1.34it/s]epoch: 40;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 59%|████████████████████████████████████████████████                                  | 41/70 [00:30<00:21,  1.34it/s]epoch: 41;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 60%|█████████████████████████████████████████████████▏                                | 42/70 [00:31<00:20,  1.34it/s]epoch: 42;\n",
      "accuracy: 0.5016741071428571;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 61%|██████████████████████████████████████████████████▎                               | 43/70 [00:32<00:20,  1.34it/s]epoch: 43;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 63%|███████████████████████████████████████████████████▌                              | 44/70 [00:32<00:19,  1.33it/s]epoch: 44;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 64%|████████████████████████████████████████████████████▋                             | 45/70 [00:33<00:18,  1.33it/s]epoch: 45;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.3638392857142857\n",
      " 66%|█████████████████████████████████████████████████████▉                            | 46/70 [00:34<00:18,  1.33it/s]epoch: 46;\n",
      "accuracy: 0.5016741071428571;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 67%|███████████████████████████████████████████████████████                           | 47/70 [00:35<00:17,  1.32it/s]epoch: 47;\n",
      "accuracy: 0.2611607142857143;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 69%|████████████████████████████████████████████████████████▏                         | 48/70 [00:36<00:16,  1.32it/s]epoch: 48;\n",
      "accuracy: 0.2611607142857143;\n",
      "validation accuracy: 0.3549107142857143\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 49/70 [00:37<00:15,  1.32it/s]epoch: 49;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 71%|██████████████████████████████████████████████████████████▌                       | 50/70 [00:38<00:15,  1.31it/s]epoch: 50;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 51/70 [00:38<00:14,  1.31it/s]epoch: 51;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.265625\n",
      " 74%|████████████████████████████████████████████████████████████▉                     | 52/70 [00:39<00:13,  1.31it/s]epoch: 52;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 76%|██████████████████████████████████████████████████████████████                    | 53/70 [00:40<00:13,  1.31it/s]epoch: 53;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 54/70 [00:41<00:12,  1.31it/s]epoch: 54;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 79%|████████████████████████████████████████████████████████████████▍                 | 55/70 [00:42<00:11,  1.30it/s]epoch: 55;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 56/70 [00:43<00:10,  1.30it/s]epoch: 56;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 81%|██████████████████████████████████████████████████████████████████▊               | 57/70 [00:43<00:10,  1.30it/s]epoch: 57;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 83%|███████████████████████████████████████████████████████████████████▉              | 58/70 [00:45<00:09,  1.29it/s]epoch: 58;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 84%|█████████████████████████████████████████████████████████████████████             | 59/70 [00:45<00:08,  1.29it/s]epoch: 59;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 86%|██████████████████████████████████████████████████████████████████████▎           | 60/70 [00:46<00:07,  1.28it/s]epoch: 60;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 87%|███████████████████████████████████████████████████████████████████████▍          | 61/70 [00:47<00:07,  1.28it/s]epoch: 61;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 62/70 [00:48<00:06,  1.28it/s]epoch: 62;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 63/70 [00:49<00:05,  1.28it/s]epoch: 63;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▉       | 64/70 [00:50<00:04,  1.28it/s]epoch: 64;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 93%|████████████████████████████████████████████████████████████████████████████▏     | 65/70 [00:51<00:03,  1.27it/s]epoch: 65;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 66/70 [00:51<00:03,  1.27it/s]epoch: 66;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▍   | 67/70 [00:52<00:02,  1.27it/s]epoch: 67;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▋  | 68/70 [00:53<00:01,  1.27it/s]epoch: 68;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 99%|████████████████████████████████████████████████████████████████████████████████▊ | 69/70 [00:54<00:00,  1.27it/s]epoch: 69;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 70/70 [00:55<00:00,  1.26it/s]\n",
      "90\n",
      "  0%|                                                                                           | 0/90 [00:00<?, ?it/s]epoch: 0;\n",
      "accuracy: 0.24107142857142858;\n",
      "validation accuracy: 0.2611607142857143\n",
      "  1%|▉                                                                                  | 1/90 [00:01<01:34,  1.06s/it]epoch: 1;\n",
      "accuracy: 0.23549107142857142;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.2611607142857143\n",
      "  2%|█▊                                                                                 | 2/90 [00:02<01:28,  1.00s/it]epoch: 2;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.375\n",
      "  3%|██▊                                                                                | 3/90 [00:02<01:26,  1.01it/s]epoch: 3;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  4%|███▋                                                                               | 4/90 [00:03<01:24,  1.02it/s]epoch: 4;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.27232142857142855\n",
      "  6%|████▌                                                                              | 5/90 [00:04<01:22,  1.03it/s]epoch: 5;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      "  7%|█████▌                                                                             | 6/90 [00:05<01:21,  1.03it/s]epoch: 6;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      "  8%|██████▍                                                                            | 7/90 [00:06<01:20,  1.03it/s]epoch: 7;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.3080357142857143\n",
      "  9%|███████▍                                                                           | 8/90 [00:07<01:19,  1.03it/s]epoch: 8;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 10%|████████▎                                                                          | 9/90 [00:08<01:18,  1.03it/s]epoch: 9;\n",
      "accuracy: 0.38839285714285715;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 11%|█████████                                                                         | 10/90 [00:09<01:17,  1.03it/s]epoch: 10;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 12%|██████████                                                                        | 11/90 [00:10<01:16,  1.03it/s]epoch: 11;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 13%|██████████▉                                                                       | 12/90 [00:11<01:15,  1.03it/s]epoch: 12;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 14%|███████████▊                                                                      | 13/90 [00:12<01:14,  1.03it/s]epoch: 13;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.359375\n",
      " 16%|████████████▊                                                                     | 14/90 [00:14<01:16,  1.01s/it]epoch: 14;\n",
      "accuracy: 0.2572544642857143;\n",
      "validation accuracy: 0.375\n",
      " 17%|█████████████▋                                                                    | 15/90 [00:15<01:16,  1.01s/it]epoch: 15;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 18%|██████████████▌                                                                   | 16/90 [00:16<01:16,  1.03s/it]epoch: 16;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 19%|███████████████▍                                                                  | 17/90 [00:17<01:15,  1.03s/it]epoch: 17;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 20%|████████████████▍                                                                 | 18/90 [00:19<01:16,  1.06s/it]epoch: 18;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 21%|█████████████████▎                                                                | 19/90 [00:20<01:16,  1.08s/it]epoch: 19;\n",
      "accuracy: 0.2572544642857143;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 22%|██████████████████▏                                                               | 20/90 [00:21<01:16,  1.09s/it]epoch: 20;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 23%|███████████████████▏                                                              | 21/90 [00:23<01:15,  1.10s/it]epoch: 21;\n",
      "accuracy: 0.2611607142857143;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 24%|████████████████████                                                              | 22/90 [00:24<01:14,  1.10s/it]epoch: 22;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 26%|████████████████████▉                                                             | 23/90 [00:25<01:13,  1.09s/it]epoch: 23;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 27%|█████████████████████▊                                                            | 24/90 [00:26<01:12,  1.09s/it]epoch: 24;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 28%|██████████████████████▊                                                           | 25/90 [00:27<01:11,  1.10s/it]epoch: 25;\n",
      "accuracy: 0.26953125;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 29%|███████████████████████▋                                                          | 26/90 [00:28<01:11,  1.11s/it]epoch: 26;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 30%|████████████████████████▌                                                         | 27/90 [00:29<01:09,  1.11s/it]epoch: 27;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 31%|█████████████████████████▌                                                        | 28/90 [00:31<01:08,  1.11s/it]epoch: 28;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 32%|██████████████████████████▍                                                       | 29/90 [00:32<01:07,  1.11s/it]epoch: 29;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 33%|███████████████████████████▎                                                      | 30/90 [00:33<01:06,  1.11s/it]epoch: 30;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 34%|████████████████████████████▏                                                     | 31/90 [00:34<01:05,  1.11s/it]epoch: 31;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 36%|█████████████████████████████▏                                                    | 32/90 [00:35<01:04,  1.11s/it]epoch: 32;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 37%|██████████████████████████████                                                    | 33/90 [00:36<01:03,  1.12s/it]epoch: 33;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.265625\n",
      " 38%|██████████████████████████████▉                                                   | 34/90 [00:38<01:03,  1.13s/it]epoch: 34;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 39%|███████████████████████████████▉                                                  | 35/90 [00:39<01:02,  1.13s/it]epoch: 35;\n",
      "accuracy: 0.23493303571428573;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 40%|████████████████████████████████▊                                                 | 36/90 [00:40<01:01,  1.13s/it]epoch: 36;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 41%|█████████████████████████████████▋                                                | 37/90 [00:41<01:00,  1.13s/it]epoch: 37;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 42%|██████████████████████████████████▌                                               | 38/90 [00:43<00:58,  1.13s/it]epoch: 38;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 43%|███████████████████████████████████▌                                              | 39/90 [00:44<00:57,  1.13s/it]epoch: 39;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 44%|████████████████████████████████████▍                                             | 40/90 [00:45<00:56,  1.14s/it]epoch: 40;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.34375\n",
      " 46%|█████████████████████████████████████▎                                            | 41/90 [00:46<00:55,  1.14s/it]epoch: 41;\n",
      "accuracy: 0.25613839285714285;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 47%|██████████████████████████████████████▎                                           | 42/90 [00:47<00:54,  1.14s/it]epoch: 42;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 48%|███████████████████████████████████████▏                                          | 43/90 [00:48<00:53,  1.13s/it]epoch: 43;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 49%|████████████████████████████████████████                                          | 44/90 [00:49<00:52,  1.14s/it]epoch: 44;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 50%|█████████████████████████████████████████                                         | 45/90 [00:51<00:51,  1.14s/it]epoch: 45;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 51%|█████████████████████████████████████████▉                                        | 46/90 [00:52<00:49,  1.14s/it]epoch: 46;\n",
      "accuracy: 0.23604910714285715;\n",
      "validation accuracy: 0.265625\n",
      " 52%|██████████████████████████████████████████▊                                       | 47/90 [00:53<00:48,  1.14s/it]epoch: 47;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 53%|███████████████████████████████████████████▋                                      | 48/90 [00:54<00:47,  1.14s/it]epoch: 48;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 54%|████████████████████████████████████████████▋                                     | 49/90 [00:55<00:46,  1.14s/it]epoch: 49;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.32142857142857145\n",
      " 56%|█████████████████████████████████████████████▌                                    | 50/90 [00:57<00:45,  1.14s/it]epoch: 50;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 57%|██████████████████████████████████████████████▍                                   | 51/90 [00:58<00:44,  1.14s/it]epoch: 51;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 58%|███████████████████████████████████████████████▍                                  | 52/90 [00:59<00:43,  1.14s/it]epoch: 52;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 59%|████████████████████████████████████████████████▎                                 | 53/90 [01:00<00:42,  1.14s/it]epoch: 53;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 60%|█████████████████████████████████████████████████▏                                | 54/90 [01:01<00:41,  1.14s/it]epoch: 54;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 61%|██████████████████████████████████████████████████                                | 55/90 [01:02<00:39,  1.14s/it]epoch: 55;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 62%|███████████████████████████████████████████████████                               | 56/90 [01:03<00:38,  1.14s/it]epoch: 56;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 63%|███████████████████████████████████████████████████▉                              | 57/90 [01:04<00:37,  1.14s/it]epoch: 57;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 64%|████████████████████████████████████████████████████▊                             | 58/90 [01:06<00:36,  1.14s/it]epoch: 58;\n",
      "accuracy: 0.5016741071428571;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 66%|█████████████████████████████████████████████████████▊                            | 59/90 [01:07<00:35,  1.14s/it]epoch: 59;\n",
      "accuracy: 0.23660714285714285;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 67%|██████████████████████████████████████████████████████▋                           | 60/90 [01:08<00:34,  1.14s/it]epoch: 60;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 68%|███████████████████████████████████████████████████████▌                          | 61/90 [01:09<00:33,  1.14s/it]epoch: 61;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 69%|████████████████████████████████████████████████████████▍                         | 62/90 [01:10<00:32,  1.14s/it]epoch: 62;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 70%|█████████████████████████████████████████████████████████▍                        | 63/90 [01:12<00:30,  1.14s/it]epoch: 63;\n",
      "accuracy: 0.26004464285714285;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 71%|██████████████████████████████████████████████████████████▎                       | 64/90 [01:13<00:29,  1.14s/it]epoch: 64;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 72%|███████████████████████████████████████████████████████████▏                      | 65/90 [01:14<00:28,  1.15s/it]epoch: 65;\n",
      "accuracy: 0.2622767857142857;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 73%|████████████████████████████████████████████████████████████▏                     | 66/90 [01:15<00:27,  1.15s/it]epoch: 66;\n",
      "accuracy: 0.23493303571428573;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 74%|█████████████████████████████████████████████████████████████                     | 67/90 [01:16<00:26,  1.15s/it]epoch: 67;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 76%|█████████████████████████████████████████████████████████████▉                    | 68/90 [01:18<00:25,  1.15s/it]epoch: 68;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2700892857142857\n",
      " 77%|██████████████████████████████████████████████████████████████▊                   | 69/90 [01:19<00:24,  1.15s/it]epoch: 69;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 78%|███████████████████████████████████████████████████████████████▊                  | 70/90 [01:20<00:23,  1.15s/it]epoch: 70;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 79%|████████████████████████████████████████████████████████████████▋                 | 71/90 [01:22<00:21,  1.16s/it]epoch: 71;\n",
      "accuracy: 0.26450892857142855;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 80%|█████████████████████████████████████████████████████████████████▌                | 72/90 [01:23<00:20,  1.16s/it]epoch: 72;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 81%|██████████████████████████████████████████████████████████████████▌               | 73/90 [01:24<00:19,  1.16s/it]epoch: 73;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 82%|███████████████████████████████████████████████████████████████████▍              | 74/90 [01:25<00:18,  1.16s/it]epoch: 74;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 75/90 [01:27<00:17,  1.16s/it]epoch: 75;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 84%|█████████████████████████████████████████████████████████████████████▏            | 76/90 [01:28<00:16,  1.16s/it]epoch: 76;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 86%|██████████████████████████████████████████████████████████████████████▏           | 77/90 [01:29<00:15,  1.16s/it]epoch: 77;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 87%|███████████████████████████████████████████████████████████████████████           | 78/90 [01:30<00:13,  1.16s/it]epoch: 78;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 88%|███████████████████████████████████████████████████████████████████████▉          | 79/90 [01:32<00:12,  1.17s/it]epoch: 79;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 89%|████████████████████████████████████████████████████████████████████████▉         | 80/90 [01:33<00:11,  1.17s/it]epoch: 80;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 81/90 [01:34<00:10,  1.17s/it]epoch: 81;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▋       | 82/90 [01:35<00:09,  1.17s/it]epoch: 82;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 92%|███████████████████████████████████████████████████████████████████████████▌      | 83/90 [01:36<00:08,  1.17s/it]epoch: 83;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.35714285714285715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|████████████████████████████████████████████████████████████████████████████▌     | 84/90 [01:38<00:07,  1.17s/it]epoch: 84;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.31026785714285715\n",
      " 94%|█████████████████████████████████████████████████████████████████████████████▍    | 85/90 [01:39<00:05,  1.17s/it]epoch: 85;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 96%|██████████████████████████████████████████████████████████████████████████████▎   | 86/90 [01:40<00:04,  1.17s/it]epoch: 86;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 97%|███████████████████████████████████████████████████████████████████████████████▎  | 87/90 [01:41<00:03,  1.17s/it]epoch: 87;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████▏ | 88/90 [01:43<00:02,  1.17s/it]epoch: 88;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 99%|█████████████████████████████████████████████████████████████████████████████████ | 89/90 [01:44<00:01,  1.17s/it]epoch: 89;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 90/90 [01:45<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    in_size = data_x.shape[1]\n",
    "    out_size = data_y.shape[1]\n",
    "    data= train_bayesian_network(data_x, data_y, in_size, out_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=[]\n",
    "accuracy_val=[]\n",
    "accuracy_train=[]\n",
    "error_training=[]\n",
    "error_vald=[]\n",
    "\n",
    "tr_x=[]\n",
    "tr_y=[]\n",
    "val_x=[]\n",
    "val_y=[]\n",
    "y_samp=[]\n",
    "from sklearn import metrics  \n",
    "batch_sizes=[1000,3000,5000,7000,9000]\n",
    "def train_bayesian_network(data_x, data_y, in_size, out_size):\n",
    "    for b in range(len(batch_sizes)):\n",
    "        training_epochs = 10\n",
    "        batch_size = batch_sizes[b]\n",
    "        print(training_epochs)\n",
    "        x_ = tf.placeholder(tf.float32, shape=(None, in_size))\n",
    "        y_ = tf.placeholder(tf.int32)\n",
    "\n",
    "        train_x, test_x, train_y2, test_y2, train_cnt = prepare_train_test_data(data_x, data_y)\n",
    "        tr_x.append(train_x)\n",
    "        tr_y.append(train_y2)\n",
    "        val_x.append(test_x)\n",
    "        val_y.append(test_y2)\n",
    "        inference, y_pre, y = build_bayesian_network(x_, y_, in_size, out_size)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with sess:\n",
    "            samples_num = 100\n",
    "            for epoch in tqdm(range(training_epochs), file=sys.stdout):\n",
    "                perm = np.random.permutation(train_cnt)\n",
    "                for i in range(0, train_cnt, batch_size):\n",
    "                    batch_x = train_x[perm[i:i + batch_size]]\n",
    "                    batch_y = train_y2[perm[i:i + batch_size]]\n",
    "                    inference.update(feed_dict={x_: batch_x, y_: batch_y})\n",
    "\n",
    "                #train\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: train_x})   \n",
    "                acc = (np.round(y_samples.sum(axis=0) / samples_num) == train_y2).mean()\n",
    "                predic_train=np.round((y_samples.sum(axis=0) / samples_num) == train_y2)\n",
    "                accuracy_train.append(acc)\n",
    "                loss_train=metrics.mean_absolute_error(train_y2, predic_train)\n",
    "                error_training.append(loss_train)\n",
    "\n",
    "\n",
    "                #validation\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: test_x})\n",
    "                tets_acc = (np.round(y_samples.sum(axis=0) / samples_num) == test_y2).mean()            \n",
    "                predic_val=np.round((y_samples.sum(axis=0) / samples_num) == test_y2)            \n",
    "                pred.append(predic_val)\n",
    "                accuracy_val.append(tets_acc)\n",
    "                loss_val=metrics.mean_absolute_error(test_y2, predic_val)\n",
    "                error_vald.append(loss_val)\n",
    "                print(\"epoch: {0};\\nbatch size:{1} ;\\naccuracy: {2};\\nvalidation accuracy: {3}\"\n",
    "                                .format(epoch,batch_size,acc,tets_acc))\n",
    " \n",
    "#           tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(training_epochs+1, acc, tets_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]epoch: 0;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.26171875;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 10%|████████▎                                                                          | 1/10 [00:01<00:13,  1.53s/it]epoch: 1;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.38169642857142855\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:02<00:11,  1.44s/it]epoch: 2;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.3861607142857143\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:04<00:09,  1.39s/it]epoch: 3;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:05<00:08,  1.37s/it]epoch: 4;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:06<00:06,  1.35s/it]epoch: 5;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:08<00:05,  1.35s/it]epoch: 6;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:09<00:04,  1.37s/it]epoch: 7;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.46707589285714285;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:10<00:02,  1.37s/it]epoch: 8;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:12<00:01,  1.37s/it]epoch: 9;\n",
      "batch size:1000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.2611607142857143\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.37s/it]\n",
      "10\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]epoch: 0;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.2611607142857143\n",
      " 10%|████████▎                                                                          | 1/10 [00:01<00:13,  1.55s/it]epoch: 1;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.23549107142857142;\n",
      "validation accuracy: 0.359375\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:02<00:11,  1.46s/it]epoch: 2;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.5016741071428571;\n",
      "validation accuracy: 0.30357142857142855\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:04<00:10,  1.46s/it]epoch: 3;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:05<00:08,  1.44s/it]epoch: 4;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:07<00:07,  1.44s/it]epoch: 5;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:08<00:05,  1.44s/it]epoch: 6;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.49776785714285715;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:10<00:04,  1.43s/it]epoch: 7;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.23604910714285715;\n",
      "validation accuracy: 0.35714285714285715\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:11<00:02,  1.43s/it]epoch: 8;\n",
      "batch size:3000 ;\n",
      "accuracy: 0.5027901785714286;\n",
      "validation accuracy: 0.36830357142857145\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:12<00:01,  1.43s/it]"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    in_size = data_x.shape[1]\n",
    "    out_size = data_y.shape[1]\n",
    "    data= train_bayesian_network(data_x, data_y, in_size, out_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning Sample Num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=[]\n",
    "accuracy_val=[]\n",
    "accuracy_train=[]\n",
    "error_training=[]\n",
    "error_vald=[]\n",
    "\n",
    "tr_x=[]\n",
    "tr_y=[]\n",
    "val_x=[]\n",
    "val_y=[]\n",
    "y_samp=[]\n",
    "from sklearn import metrics  \n",
    "sample_nums=[100,300,500,700,900]\n",
    "def train_bayesian_network(data_x, data_y, in_size, out_size):\n",
    "    for c in range(len(sample_nums)):\n",
    "        training_epochs = 10\n",
    "        batch_size = 1000\n",
    "        print(training_epochs)\n",
    "        x_ = tf.placeholder(tf.float32, shape=(None, in_size))\n",
    "        y_ = tf.placeholder(tf.int32)\n",
    "\n",
    "        train_x, test_x, train_y2, test_y2, train_cnt = prepare_train_test_data(data_x, data_y)\n",
    "        tr_x.append(train_x)\n",
    "        tr_y.append(train_y2)\n",
    "        val_x.append(test_x)\n",
    "        val_y.append(test_y2)\n",
    "        inference, y_pre, y = build_bayesian_network(x_, y_, in_size, out_size)\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with sess:\n",
    "            samples_num = sample_nums[c]\n",
    "            for epoch in tqdm(range(training_epochs), file=sys.stdout):\n",
    "                perm = np.random.permutation(train_cnt)\n",
    "                for i in range(0, train_cnt, batch_size):\n",
    "                    batch_x = train_x[perm[i:i + batch_size]]\n",
    "                    batch_y = train_y2[perm[i:i + batch_size]]\n",
    "                    inference.update(feed_dict={x_: batch_x, y_: batch_y})\n",
    "\n",
    "                #train\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: train_x})   \n",
    "                acc = (np.round(y_samples.sum(axis=0) / samples_num) == train_y2).mean()\n",
    "                predic_train=np.round((y_samples.sum(axis=0) / samples_num) == train_y2)\n",
    "                accuracy_train.append(acc)\n",
    "                loss_train=metrics.mean_absolute_error(train_y2, predic_train)\n",
    "                error_training.append(loss_train)\n",
    "\n",
    "\n",
    "                #validation\n",
    "                y_samples = y.sample(samples_num).eval(feed_dict={x_: test_x})\n",
    "                tets_acc = (np.round(y_samples.sum(axis=0) / samples_num) == test_y2).mean()            \n",
    "                predic_val=np.round((y_samples.sum(axis=0) / samples_num) == test_y2)            \n",
    "                pred.append(predic_val)\n",
    "                accuracy_val.append(tets_acc)\n",
    "                loss_val=metrics.mean_absolute_error(test_y2, predic_val)\n",
    "                error_vald.append(loss_val)\n",
    "                print(\"epoch: {0}; \\nbatch size:{1} ;\\nsumple numps:{2} ;\\naccuracy: {2};\\nvalidation accuracy: {3}\"\n",
    "                                .format(epoch,batch_size,samples_num,acc,tets_acc))\n",
    " \n",
    "#           tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(training_epochs+1, acc, tets_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    in_size = data_x.shape[1]\n",
    "    out_size = data_y.shape[1]\n",
    "    data= train_bayesian_network(data_x, data_y, in_size, out_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy dan validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pred=[]\n",
    "accuracy_val=[]\n",
    "accuracy_train=[]\n",
    "error_training=[]\n",
    "error_vald=[]\n",
    "\n",
    "tr_x=[]\n",
    "tr_y=[]\n",
    "val_x=[]\n",
    "val_y=[]\n",
    "y_samp=[]\n",
    "from sklearn import metrics  \n",
    "def train_bayesian_network(data_x, data_y, in_size, out_size):\n",
    "    training_epochs = 10\n",
    "    batch_size = 1000\n",
    "\n",
    "\n",
    "    x_ = tf.placeholder(tf.float32, shape=(None, in_size))\n",
    "    y_ = tf.placeholder(tf.int32)\n",
    "\n",
    "    train_x, test_x, train_y2, test_y2, train_cnt = prepare_train_test_data(data_x, data_y)\n",
    "    tr_x.append(train_x)\n",
    "    tr_y.append(train_y2)\n",
    "    val_x.append(test_x)\n",
    "    val_y.append(test_y2)\n",
    "    inference, y_pre, y = build_bayesian_network(x_, y_, in_size, out_size)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    with sess:\n",
    "        samples_num = 100\n",
    "        for epoch in tqdm(range(training_epochs), file=sys.stdout):\n",
    "            perm = np.random.permutation(train_cnt)\n",
    "            for i in range(0, train_cnt, batch_size):\n",
    "                batch_x = train_x[perm[i:i + batch_size]]\n",
    "                batch_y = train_y2[perm[i:i + batch_size]]\n",
    "                inference.update(feed_dict={x_: batch_x, y_: batch_y})\n",
    "            \n",
    "            #train\n",
    "            y_samples = y.sample(samples_num).eval(feed_dict={x_: train_x})   \n",
    "            acc = (np.round(y_samples.sum(axis=0) / samples_num) == train_y2).mean()\n",
    "            predic_train=np.round((y_samples.sum(axis=0) / samples_num) == train_y2)\n",
    "            accuracy_train.append(acc)\n",
    "            loss_train=metrics.mean_absolute_error(train_y2, predic_train)\n",
    "            error_training.append(loss_train)\n",
    "            \n",
    "            \n",
    "            #validation\n",
    "            y_samples = y.sample(samples_num).eval(feed_dict={x_: test_x})\n",
    "            tets_acc = (np.round(y_samples.sum(axis=0) / samples_num) == test_y2).mean()            \n",
    "            predic_val=np.round((y_samples.sum(axis=0) / samples_num) == test_y2)            \n",
    "            pred.append(predic_val)\n",
    "            accuracy_val.append(tets_acc)\n",
    "            loss_val=metrics.mean_absolute_error(test_y2, predic_val)\n",
    "            error_vald.append(loss_val)\n",
    "\n",
    "\n",
    "            tqdm.write('epoch:\\t{}\\taccuracy:\\t{}\\tvaridation accuracy:\\t{}'.format(epoch + 1, acc, tets_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\t1\taccuracy:\t0.26171875\tvaridation accuracy:\t0.2611607142857143                                                  \n",
      "epoch:\t2\taccuracy:\t0.23660714285714285\tvaridation accuracy:\t0.375                                                      \n",
      "epoch:\t3\taccuracy:\t0.5027901785714286\tvaridation accuracy:\t0.38169642857142855                                         \n",
      "epoch:\t4\taccuracy:\t0.26171875\tvaridation accuracy:\t0.359375                                                            \n",
      "epoch:\t5\taccuracy:\t0.5027901785714286\tvaridation accuracy:\t0.35714285714285715                                         \n",
      "epoch:\t6\taccuracy:\t0.5027901785714286\tvaridation accuracy:\t0.35714285714285715                                         \n",
      "epoch:\t7\taccuracy:\t0.3208705357142857\tvaridation accuracy:\t0.35714285714285715                                         \n",
      "epoch:\t8\taccuracy:\t0.5027901785714286\tvaridation accuracy:\t0.2611607142857143                                          \n",
      "epoch:\t9\taccuracy:\t0.5027901785714286\tvaridation accuracy:\t0.38169642857142855                                         \n",
      "epoch:\t10\taccuracy:\t0.23549107142857142\tvaridation accuracy:\t0.2611607142857143                                        \n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.62it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    in_size = data_x.shape[1]\n",
    "    out_size = data_y.shape[1]\n",
    "    data= train_bayesian_network(data_x, data_y, in_size, out_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2512f488080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracy_train, \"o-\",color=\"b\",)\n",
    "plt.plot(accuracy_val, \"o-\",color=\"g\",)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train error dan validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXd4VFX6xz8nBUIghN4SSFBBaiCU\nkBGliEhJEEFBiuviT0VRRNR1LSiIaxbWRpGi2HeJBY01QUAQBKT3jiAmEHoNJZSU8/vjZCAJk2Qm\nmTv3TnI+zzNPyJ1bXibJ/d7zViGlRKPRaDQaAB+zDdBoNBqNddCioNFoNJqraFHQaDQazVW0KGg0\nGo3mKloUNBqNRnMVLQoajUajuYoWBY2mAIQQ4UIIKYTwc2LfYUKI5Z6wS6MxEi0KmlKBECJZCHFF\nCFEj3/ZNOTf2cHMsyyMu5/O97jPLJo2mILQoaEoTfwGD7d8IIVoCFcwz5zqqSCkr5Xp95WgnIYSv\nM9sKw5nVjUbjCC0KmtLE/4AHcn3/d+C/uXcQQgQLIf4rhDguhEgRQrwshPDJec9XCPGWEOKEEGIf\nEOPg2I+EEIeFEAeFEK+7erN2hBDiUyHETCHEXCHEBaBrAdsKs32YEOJ3IcQkIcQp4NWS2qUpm2hR\n0JQmVgGVhRBNc27W9wGz8+3zLhAM3AB0RonIgznvPQLEApFAO+DefMd+BmQCN+XscyfwsJtsHwLE\nAUHA8gK2FWY7QAdgH1Ar5ziNxmW0KGhKG/bVQndgF3DQ/kYuoXhRSnlOSpkMvA38LWeXgcBkKeUB\nKeUpYEKuY2sDvYDRUsoLUspjwCRgkAu2nRBCnMn1aprrvR+klL9LKbOllJfybwMyirAd4JCU8l0p\nZaaU8qILdmk0V9F+R01p43/AUqAh+VxHQA2gHJCSa1sKEJLz73rAgXzv2QkD/IHDQgj7Np98+xdF\nDSllZgHvOTpP7m1F2V7QOTQal9ArBU2pQkqZggo49wa+zff2CdQTd1iubQ24tpo4DNTP956dA8Bl\n1I29Ss6rspSyubtML2JbUbYXdA6NxiW0KGhKIw8Bt0spL+TeKKXMAuYAcUKIICFEGPAM1+IOc4BR\nQohQIURV4IVcxx4GFgBvCyEqCyF8hBA3CiE6e+I/5ITtGo1b0KKgKXVIKf+UUq4r4O0ngQuogOxy\n4HPg45z3PgDmA5uBDVy/0ngA5cLZAZwGvgHqumDamXx1Cs+4cGxRtms0bkHoITsajUajsaNXChqN\nRqO5ihYFjUaj0VxFi4JGo9ForqJFQaPRaDRX8britRo1asjw8HCzzdBoNBqvYv369SeklDWL2s/r\nRCE8PJx16wrKNtRoNBqNI4QQKUXvpd1HGo1Go8mFFgWNRqPRXEWLgkaj0Wiu4nUxBY1GU7rIyMgg\nNTWVS5cuFb2zpkgCAgIIDQ3F39+/WMdrUdBoNKaSmppKUFAQ4eHh5GpLrikGUkpOnjxJamoqDRs2\nLNY5yoT7KD4ewsPBx0d9jY832yKNRmPn0qVLVK9eXQuCGxBCUL169RKtukr9SiE+HoYPh/R09X1K\nivoeYOhQ8+zSaDTX0ILgPkr6WZb6lcKYMdcEwU56utqu0Wg0mryUelHYv9+17RqNpmxx5swZZsyY\n4fJxvXv35syZMwZYZC6lXhQaNHBtu0ajsTbujhEWJApZWVmFHjd37lyqVKlSsotbkFIvCnFxEBiY\nd5uvr9qu0Wi8C3uMMCUFpLwWIyyJMLzwwgv8+eeftG7dmvbt29O1a1eGDBlCy5YtAbj77rtp27Yt\nzZs3Z9asWVePCw8P58SJEyQnJ9O0aVMeeeQRmjdvzp133snFixdL+l81jVIfaLYHk8eMUS6j4GA4\ncwYqVTLXLo1Gcz2jR8OmTQW/v2oVXL6cd1t6Ojz0EHzwgeNjWreGyZMLPufEiRPZtm0bmzZtYsmS\nJcTExLBt27arKZ0ff/wx1apV4+LFi7Rv35577rmH6tWr5znHnj17+OKLL/jggw8YOHAgCQkJ3H//\n/c78ly1HqV8pgBKG5GTIzoZjx6BFC3jySTh/3mzLNBqNK+QXhKK2F4eoqKg8Of5Tp06lVatWREdH\nc+DAAfbs2XPdMQ0bNqR169YAtG3bluTkZPcZ5GFK/UohP/7+8N57cOutMH48vPmm2RZpNBo7hT3R\ng4ohpDjo9RkWBkuWuMeGihUrXv33kiVLWLhwIStXriQwMJAuXbo4rAEoX7781X/7+vp6tfuoTKwU\n8tOxIzz8MEyaBFu2mG2NRqNxFkcxwsDAksUIg4KCOHfunMP30tLSqFq1KoGBgezatYtVq1YV/0Je\nQpkUBYCJE6FqVXjsMeVW0mg01mfoUJg1S60MhFBfZ80qWSFq9erV6dixIy1atOC5557L817Pnj3J\nzMwkIiKCV155hejo6BL+D6yPkFKabYNLtGvXTrpryM5nn8GwYeqX6pFH3HJKjUbjIjt37qRp06Zm\nm1GqcPSZCiHWSynbFXVsmV0pADzwAHTuDM8/rwLQGo1GU9Yp06IgBMycqbKQ8q0aNRqNpkxSpkUB\noGlTJQj//S8sXmy2NRqNRmMuZV4UQBW2NWwII0a4N99Zo9FovA0tCqiUtmnTYPdueOsts63RaDQa\n89CikEPv3nDvvfD66/Dnn2Zbo9FoNOZgmCgIIT4WQhwTQmwrYr/2QogsIcS9RtniLJMng58fjByp\nmm1pNBpNfirlNE47dOgQ997r+LbVpUsXikqdnzx5Mum5hr1YpRW3kSuFT4Gehe0ghPAF/gPMN9AO\npwkJUSuFefPgm2/Mtkaj0Tgifms84ZPD8RnvQ/jkcOK3mjNft169enxTghtFflGwSituw0RBSrkU\nOFXEbk8CCYBlqgSeeAIiI+Gpp+DsWbOt0Wg0uYnfGs/wn4aTkpaCRJKSlsLwn4aXSBief/75PPMU\nXn31VcaPH0+3bt1o06YNLVu25IcffrjuuOTkZFq0aAHAxYsXGTRoEBEREdx33315eh+NGDGCdu3a\n0bx5c8aNGweoJnuHDh2ia9eudO3aFbjWihvgnXfeoUWLFrRo0YLJOQ2hPNWi27SGeEKIEKAfcDvQ\n3iw78uPnpxrmRUfDK6/AlClmW6TRlB1GzxvNpiMF985elbqKy1l5UwTTM9J56IeH+GC9497Zreu0\nZnLPgjvtDRo0iNGjR/P4448DMGfOHObNm8fTTz9N5cqVOXHiBNHR0dx1110Fzj+eOXMmgYGBbNmy\nhS1bttCmTZur78XFxVGtWjWysrLo1q0bW7ZsYdSoUbzzzjssXryYGjVq5DnX+vXr+eSTT1i9ejVS\nSjp06EDnzp2pWrWqR1p0mxlongw8L6UsfLwRIIQYLoRYJ4RYd/z4ccMNi4pS6anTpsH69YZfTqPR\nOEl+QShquzNERkZy7NgxDh06xObNm6latSp169blpZdeIiIigjvuuIODBw9y9OjRAs+xdOnSqzfn\niIgIIiIirr43Z84c2rRpQ2RkJNu3b2fHjh2F2rN8+XL69etHxYoVqVSpEv3792fZsmWAZ1p0m9k6\nux3wZY7y1gB6CyEypZTf599RSjkLmAWq95EnjIuLg4QE1TBv1So1rU2j0RhLYU/0AOGTw0lJu753\ndlhwGEuGLSn2de+9916++eYbjhw5wqBBg4iPj+f48eOsX78ef39/wsPDHbbMzo2jVcRff/3FW2+9\nxdq1a6latSrDhg0r8jyF9aPzRItu01YKUsqGUspwKWU48A3wuCNBMIsqVVRr7XXrlDtJo9GYT1y3\nOAL98/bODvQPJK5byebrDho0iC+//JJvvvmGe++9l7S0NGrVqoW/vz+LFy8mxdEQh1x06tSJ+JyZ\noNu2bWNLTk/+s2fPUrFiRYKDgzl69Cg///zz1WMKatndqVMnvv/+e9LT07lw4QLfffcdt912W4n+\nf65g2EpBCPEF0AWoIYRIBcYB/gBSSq+4zQ4aBB9/DC+9BP37Q926Zluk0ZRthrZUPbLHLBrD/rT9\nNAhuQFy3uKvbi0vz5s05d+4cISEh1K1bl6FDh9KnTx/atWtH69atadKkSaHHjxgxggcffJCIiAha\nt25NVFQUAK1atSIyMpLmzZtzww030LFjx6vHDB8+nF69elG3bl0W5+qx06ZNG4YNG3b1HA8//DCR\nkZEem+ZWpltnO8OePdCyJfTrB1984bHLajRlBt062/3o1tkG0qgRvPgifPklLFhgtjUajUZjLFoU\nnOD555U4PP44ePHo1atYpfhHo9FYDy0KThAQADNmqJ5IEyeabU3JMKL4R6MpKd7mxrYyJf0stSg4\nyR13wJAhShR27zbbmuIzZtEY0jPS82xLz0hnzKIxJlmkKesEBARw8uRJLQxuQErJyZMnCQgIKPY5\nzKxT8DrefhuSkpQbaeFCNbnN29iftt+l7RqN0YSGhpKamoonClPLAgEBAYSGhhb7eC0KLlCnDkyY\noETh889haMmy4EyhQXADh8U/DYIbmGCNRgP+/v40bNjQbDM0OWj3kYsMH67aYDzzDJw+bbY1rjM6\nevR129xR/KPRaEoHWhRcxNdXVTifOKGK2ryNRX8topxPOepVqgdAcPlgZvWZVeLiH41GUzrQolAM\nIiNh1Ch4/33VF8lb+HH3jyT+kUhctzgOPnuQVrVbERUSpQVBo9FcRYtCMXntNahXTzXMy8w025qi\nSc9IZ9TPo2heszlPdXgKAFuojdUHV5Mts022TqPRWAUtCsUkKEjNWti8Gd5912xriubfy/5NSloK\n03tPx9/XHwBbfRtnL59lx/HCW/lqNJqygxaFEtC/P/TurYbxHDhgtjUF88fJP3hzxZvcH3E/ncM7\nX91uC7UBanCJRqPRgBaFEiGEGsSTlQWjr0/qsQRSSkbOHUmAXwBvdn8zz3s3VbuJ6hWqs/LASpOs\n02g0VkOLQglp2BDGjoVvv4XERLOtuZ5vdnzDL/t+4fWur1OnUp087wkhiA6NZmWqFgWNRqPQouAG\nnn0WmjaFkSMhPb3o/T3FucvnGD1/NK3rtGZE+xEO97GF2th5YienL3ph0YVGo3E7WhTcQLlyqnYh\nJQX+9S+zrbnG+N/Gc+jcIWbGzMTPx3HxenRoNABrDq7xpGkajcaiaFFwE506wbBh8NZbsH272dbA\ntmPbmLxqMg9HPnz1xu+IqJAofISPdiFpNBpAi4JbeeMNqFxZ1S5km5j6L6XkiblPEBwQzIQ7JhS6\nb1D5IFrUaqFFQaPRAFoU3ErNmkoYli+Hzz4zz47ZW2azNGUpE7tNpEZgjSL3t4XaWJ2qi9g0Go0W\nBbfz4IPQsSM895zqj+Rpzlw6wz9++QcdQjrwUJuHnDomOjSatMtp7Dqxy2DrNBqN1dGi4GZ8fGDm\nTEhLU2M8Pc0rv77CifQTzIiZgY9w7sdrL2LT9QoajUaLggG0bKlaa3/8MSxb5rnrbji8gRnrZjCi\n3Qja1G3j9HGNqzemWoVqOq6g0Wi0KBjF2LHQoAGMGAFXrhh/vWyZzeNJj1MjsAav3/66S8fai9h0\nuwuNRqNFwSAqVlQtMLZvh0mTjL/exxs/ZvXB1bzZ/U2qBFRx+fjokGh2HN9B2qU0A6zTaDTeghYF\nA+nTB+6+G8aPh+Rk465zIv0Ezy98ntsa3MbfIv5WrHPY6tuQSFYfXO1m6zQajTehRcFgpkxRweeR\nI0FKY67x4sIXSbuUxvTe0xFCFOscUSFRCIRHg83x8RAerj6f8HD1vUajMRctCgbToIFaKSQlwfff\nu//8q1JX8eHGDxkdPZqWtVsW+zyVy1emRa0WrDrombhCfLyad52SosQyJUV9r4VBozEXLQoeYNQo\niIhQX8+dc995s7KzeDzpceoF1WNc53ElPp892OyJIrYxY65vHpierrZrNBrz0KLgAfz9VcO81FQI\nCXGfu2TmuplsPLKRST0mEVQ+qMR22kJtnLl0ht0ndpf4XEWxf79r2zUajWfQouAh9u0DPz+1UnCH\nu+To+aO8/OvL3HHDHQxoNsAtNtrq5xSxeaBeoUED17ZrPIOO81gTT/5ctCh4iDFjIDMz77aSuEue\n++U50jPSmdZrWrGDy/lpXL0xVQKqeKReIS4OfH3zbgsMVNs15qDjPNbE0z8XLQoewp3ukqUpS/nf\nlv/x3C3PcXONm0tmWC58hI/HJrHddZf6GpTj9fLzg1mzYOhQwy+tKQAd57Emnv65aFHwEO5yl2Rk\nZfB40uOEBYcxppP7fytsoTa2H9tueBFbUpKabT13Lnz4oVpFNW5s6CU1RaDjPNbE0z8XLQoeIi5O\nuUdyUxx3yZTVU9h+fDtTek4h0D+w6ANcxBaqitiMnsSWkAB16sAtt0D//ioY/8UXhl5SUwQ6zmNN\nPP1z0aLgIYYOVe6RsLBr215+2TV3SerZVF5d8ioxjWK46+a73G8k14rYjIwrpKerFUK/fipwVrUq\n9O4NX36pVg8ac4iLg/Ll827TcR7ziYuD/GFDI38uWhQ8yNChqt3F0aPqZnjhgmvHPzP/GbJkFlN7\nTXVbcDk/wQHBNKvZzNC4wvz5ShjuuefatsGD4fBhWLrUsMtqimDoUOjWLe+2F1/UcR6z6dpVBZir\nVFHiEBZmbPxNi4IJ1KoFXbrA11873/piwZ8L+HrH17x464vcUPUGQ+2zhdoMLWJLSIDq1aFz52vb\n+vRRTQQ//9yQS2qcZN8+uPNOOHZM3YDMHCurUcydq77+9pv6eSQnGyvUhomCEOJjIcQxIcS2At4f\nKoTYkvNaIYRoZZQtVmTAAPjjD9i6teh9L2deZuTckdxU7Sb+2fGfhttmq2/j9KXT7Dm5x+3nvnwZ\nfvoJ+vZVGUd2AgNV88CEBLWPxvPs3Qu7dkFMjBot26EDJCaabZUmKQnq11dzWjyBkSuFT4Gehbz/\nF9BZShkB/AuYZaAtlqN/f+VC+vrrovd9a8Vb7Dm1h2m9phHgF2C4bdGh0YAxRWy//gpnz+Z1HdkZ\nMgROn1buJY3nSUpSX2Ni1NfYWFi7Fo4cMc+mss7ly/DLL+pnYpDH+DoMEwUp5VLgVCHvr5BSns75\ndhUQapQtVqRWLeU+mTOncBdS8plk4pbFcU/Te+hxUw+P2NakRhOqBFQxpGNqQgJUrny97xqge3fl\nVtJZSOaQlARNmsCNN6rv7eLw88/m2VTW+e03FXuMjfXcNa0SU3gIKPBXTwgxXAixTgix7vjx4x40\ny1gGDizahfTUvKfwET5M6uGBST05+AgfOoR0cPtKITNTdYqNjb0+ywVUWuqAAfDjj3D+vFsvrSmC\nc+dgyZK8N59WrVSvLu1CMo/ERAgIUMFmT2G6KAghuqJEocAx91LKWVLKdlLKdjVr1vSccQZTlAsp\n8Y9Eftz9I2M7j6V+cH2P2hYdGs22Y9s4d9l9bV2XLoWTJx27juwMHqwyk3780W2X1TjBwoWQkXFt\ndQDKXRETAwsWeGakrCYvUipR6Nbt+honIzFVFIQQEcCHQF8p5UkzbTEDuwvJURZSekY6T/78JE1r\nNGV09GiP22ZEEVtCgvrl7llIpOnWWyE0VLuQPE1iIgQHQ8eOebfHxqpVm04V9jy7dsFff+UVak9g\nmigIIRoA3wJ/k1L+YZYdZjNwIOzefb0LacKyCSSfSWZGzAzK+ZbzuF0dQjsA7gs2Z2fDd99Br16F\nP/X4+MCgQTBvnlpVaIwnO1ulPfbsqVx4uenWTbkv7EFojeewu+1KjSgIIb4AVgI3CyFShRAPCSEe\nE0I8lrPLWKA6MEMIsUkIsc4oW6yMIxfSnpN7eGPFGwxpOYQu4V1MsatKQBW3FrGtXKmK0wpzHdkZ\nMkTFHxIS3HJpTRFs2KAyjBzdfAIDlT9bxxU8T1KSGs7l6TYjRmYfDZZS1pVS+kspQ6WUH0kp35NS\nvpfz/sNSyqpSytY5r3ZG2WJl8ruQpJSM/HkkAX4BvNX9LVNtiw5Rk9ikG4ZLJyRAuXLOPfW0bg03\n36wL2TxFUpKKH/Tq5fj92FhVw/BHmV3Pe57Tp2H5cs+vEsACgWaNyrjZvRu2bYOEnQks+HMBr3V5\njbpBdU21y1bfxqmLp9hzqmRFbFLCt9+qlNPKlYveXwgVcF66VE2r0xhLYiJER0ONGo7ft9+Y9GrB\ncyxYoPqAeTIV1Y4WBQtgdyHNnnOe0fNG06p2K56IesJss7CF5kxiK2G9woYNajCIM64jO4MHKzH5\n6qsSXVpTBIcPw7p1hd98wsKgRQstCp4kMVHV7HTo4Plra1GwALVrKxfSB3te4+C5g8yImYGfj1/R\nBxpM05pNqVy+conjCgkJasraXS40dm3cGNq21VlIRmMvTCvKTRETA8uWQZqxYzY0qBXCzz8rd17+\n6YSeQIuCRejYbzunG0+iX9j/cUv9W8w2B7hWxFaSNtpSKlHo2lU9+bjCkCGwfr32ZRtJYqJKAY6I\nKHy/2FgV/F+wwDN2lWVWr1aZd2bEE0CLgiWQUrKo/BNwJYjwPyeabU4ebKE2th7bWuwitu3b1U3d\nFdeRnfvuU/EFvVowBntfndjYovvqREeruRc6NdV4kpLUCqGHZ7raXIcWBQvw+dbPWXn4NxofmMDc\nr2s63U7bE9jq28iW2aw9tLZYxyckqBvO3Xe7fmxIiHKrffGF8y3GNc6zdKkqTHPmidTPT7kz5s7V\n7bSNJjFRFXFWrWrO9bUomMyZS2d4dsGztK/XnlEdH76ahWQVOoSoSFdxXUgJCeoXvE6d4l1/8GCV\nmbVxY/GO1xRMUpIqTLv9duf2j42F48dV51SNMezfD1u2mOc6Ai0KpjN28ViOXTjGjJgZ3HuPr9Pt\ntD1F1QpVaVKjSbGCzXv2qErt/v2Lf/177tHzm41ASjXX4vbbne+r06OHypLTWUjGYR+oY0Yqqh0t\nCiay8fBGpq+dzmPtHqNdvXZXs5CKaqftaeyT2FwtYvv2W/W1JKJQvbq6GX35pXZbuJPdu9WUNVdu\nPtWqqd5IOq5gHImJ0LChamFuFloUTCJbZvP43MepXqE6cbdfm8Cdu5DNKthCbZxIP8HeU3tdOi4h\nAdq3L3mZ/pAhqoht+fKSnUdzjfwDdZwlJka58g4edL9NZZ30dFi0yLnAv5FoUTCJTzZ+wqrUVbzR\n/Q2qVrgWUXJlIpunsE9icyWusH+/8j0XJ+soP3fdpVwcuu2F+0hMVOMdXRVs+8pCrxbcz+LFcOmS\nufEE0KLgUeK3xhM+ORyf8T4MTxxOo2qNeKDVA3n2qV0bOnVy3E7bLJrVbEZQuSCX4gp215E7RKFi\nRSUM33yjev5rSsaZM8Xvq9Osmapw1qLgfpKS1O96587m2qFFwUPEb41n+E/DSUlLQSLJltkcOHuA\nL7ZdH0EdOFD1UreKC8nXx5cOoa5NYktIUAVRN93kHhuGDFEFPb/84p7zlWUWLFCFaMUJZgqhjlu4\nUD3VatyDfaDOHXeojDAz0aLgIcYsGkN6RnqebZcyLzFm0Zjr9rWiC8kWamPL0S2cv1L0nMwjR+D3\n392zSrDTo4fK29YupJKTlKSCxtHRxTs+Jkb5v5cscatZZZpt2+DAAXOzjuxoUfAQ+9P2O73dii6k\n6NBosmU26w4VPfbiu++U3e4UhXLl4N571Yzn9PSi99c4JitLpT2WpK9O164qxqNTU92H/bPs3dtc\nO0CLgsdoEOw4olfQdrsLaft2I61yHnuw2ZmOqQkJqqFds2butWHwYLhwQeXXa4rH2rVw4kTJnkgD\nAtREtqQk6zy0eDuJidCmDdSrZ7YlWhQ8Rly3uOs6nwb6BxLXLc7h/nYX0pw5nrCuaKpVqMbN1W8u\nMq5w8qRyK9xzj/vT6jp1Un80upCt+CQmuqevTmwsJCfDjh1uMatMc+IErFplDdcRaFHwGH0a98FX\n+BLoH4hAEBYcxqw+sxjacqjD/a3oQrLVt7EydWWhRWw//qhcFO50Hdnx9VVN8ubOVZOpNK6TmKgK\n0EraV8eeuaSzkErOvHmqMNPsVFQ7WhQ8xGebPuNy1mUW/30x2eOySR6dXKAg2BkwwGIupJBoTqSf\nYN/pfQXuk5AA4eFqKWwEQ4aotFR7yqvGeVJTYfNm99x8QkLU2FQdVyg5SUlqLG87iwwkLlIUhBC+\nQoinPWFMaSVbZvPumneJDo0mKiTK6eOs5kKy1c+ZxFaAC+nsWZUy2r+/cRWZbduqNFftQnId+1O9\nu9wUsbEqy+zUKfecryySmalWCr17q791K1CkGVLKLKCvB2wptczbO489p/YwKmqUS8fVqWMtF1Lz\nms2pVK5SgcHmxES4csUY15EdIdRq4ddf1ShJjfMkJam+Ok2buud8MTHK7TF/vnvOZ0VyF5yGTw4n\nfmu8W8+/YoUqJrRKPAGcdx/9LoSYJoS4TQjRxv4y1LJSxJTVU6gXVI97m93r8rFWciH5+vgSFRLF\nqoOO210kJEDdusXPf3cW+/xmq6ygvIGLF1XBWUyM+1Zx7dtDzZql14WUv+A0JS2F4T8Nd6swJCaq\nLsDdu7vtlCXGWVG4BWgOvAa8nfN6yyijShM7j+9kwZ8LGNFuBP6+/i4fb7VCNluojc1HNnPhyoU8\n2y9cUHNl+/UzfhncpInyZ+tCNudZskQJgzufSH19Vb3DvHnKDVLacFRwmp6R7rDgtLgkJSlvQOXK\nbjtliXHqz1dK2dXBy8nRHGWbd9e8S3nf8jza9tFiHW93IVmlnbYt1EaWzLquiG3ePHXTMdJ1lJsh\nQ2DNGvjzT89cz9tJTFQFZ+7uqxMbq2IKq4o/xtuyuFJwWhz27VMpvVZyHYGToiCECBZCvCOEWJfz\nelsIEWy0cd7OmUtn+GzzZwxuOZiaFWsW+zxWciFdLWLLF2xOSFCzDzp18owd992nvuqAc9HY++p0\n7+7+vjp33qlGdZam1NQrWVd4adFLSBw/hRVUcOoqxW1fbjTOLvQ/Bs4BA3NeZ4FPjDKqtPDRho9I\nz0h3OcCcH3s2jxVcSNUDq9OoWqM8bbQvX1Y3nbvvVjcIT9CgAdx2m3IhWWEFZWW2b1etzI24+QQH\nq59DaYkr/HHyDzp+3JEJyyfQJawLFfwq5Hm/gl+FAgtOXSUpSVX+N2rkltO5DWdF4UYp5Tgp5b6c\n13jgBiMN83aysrOYtnYatzU/xGQKAAAgAElEQVS4jci6kSU6V506atlvlSyk/EVsCxfCuXOecx3Z\nGTwYdu5UM201BWN0X53YWNXQLSXFmPN7AiklH274kMj3I9l3eh8JAxNYPGwxH9z1AWHBYQhUdP62\nBrcVWV/kDOfPq/kJVlslgPOicFEIcav9GyFER+CiMSaVDn764yeSzyTzVIen3HK+AQPUDdAKLiRb\nqI1jF47x15m/AOU6Cg5W/XA8yYABamWiXUiFk5QEkZGq4MwIvL26+WT6Se79+l4e+ekR1Q34sS30\nb6pmyA5tOZTk0clkj8vmociH+C3lNw6dO1Tiay5apNK3rRZPAOdF4TFguhAiWQiRDEwDihc5LSNM\nXT2VBsEN6NvEPSUeVnIh2UJzitgOrCQjA374Afr0UZ1MPUmNGspPruc3F8zJkyoX3sibT+PGqqDQ\nG11Ii/YtIuK9CH7a/RNvdn+TBX9bQEhlx+r50m0vkZmdyX+W/6fE101MhKAguPXWovf1NM5UNPsA\nN0spWwERQISUMlJKqRftBbDl6BYWJy/mifZPXNcEr7jkLmQzm+a1mlPRvyKrUlfx228q+8TTriM7\nQ4Yot8VK5+f/lCnmz1eCaaQoCKFWC7/+qlKTvYHLmZf55y//pPv/ulO5fGVWP7yaf9zyD3xEwbfE\nG6rewAOtHmDWhlkcPlf8ykkp1aqqRw/PP0g5gzMVzdnAyJx/n5VSnjXcKi/n3dXvUsGvAg+3edit\n5x040BouJD8fP6JColiZupKEBJXqeOed5tjSt6/KqNEuJMckJnqmr05srEo4+PVXY6/jDnYe34nt\nIxtvrniTx9o9xvrh652O+425bQwZWRm88fsbxb7+xo2qGt+K8QRw3n30ixDiH0KI+kKIavaXoZZ5\nKSfSTzB762z+FvE3qlVw70dkdyFZoZLXFmpj89HNfPtTOr17K2Ewg6AgNb95zpzSWUBVEjzZV6dT\nJ6hUydpxBSkl7617j7az2nLg7AF+GPQDM2JmEOjv/C/vjdVu5P6I+3lv/XscOX+kWHYkJam/4169\ninW44Tj7q/J/wBPAUmB9zqvoEVxlkA83fMilzEs82eFJt5/bSi4kW30bmdmZHPNdb5rryM7gwXD8\nuAreaa6xcqVqMe6JJ9Jy5dRq0aqDd45fOE7fL/syImkEt4XdxpbHtnDXzXcV61wvd3qZjKwM3vz9\nzWIdn5gIUVGqPb4VcTamcL+UsmG+l05JzUdGVgbT106nW8NutKjVwpBrWMWF1CGkAwC+4StNXwb3\n6qWyn3Tbi7wkJqrsLE+59mJiVHtuq6UIz987n4j3Ipj/53wm95jMz0N/pm5Q3WKf76ZqNzE0Yigz\n183k6PmjLh179KiqxDf7b6YwnI0p6D5HTvD9ru9JPZvKqA4lK1YrDKu4kGoE1sQv7SZqRq4kKMhc\nW8qXV4Hu775TrTY0Ck/31bHXQVglC+lS5iWenvc0PeN7Ur1CddY+spanop8qNJjsLC/f9jKXsy7z\n1grXbo0//6y+WjEV1Y6zn84CIcQ9QhjVJb90MGX1FG6oegMxjYx7DLCKC2ndOshMtpFevfBJbJ5i\n8GBVQGdln7YnSU5Wq0lP3nzq1FGdU63wM9h2bBtRH0QxefVknox6krWPrCWidoTbzt+oeiOGtBzC\n9LXTOXbhmNPHJSaqkbKtW7vNFLfjrCg8A8wBLgshzgohzgkhdBZSLtYfWs/vB35nZPuR+Pr4Gnot\nKxSyJSSAz6FozmYfJSXN/FLWrl2Vj1ZnISncPVDHWWJiVHO848c9e107UkreXf0u7Wa14+iFoyQN\nSWJqr6lU8K9Q9MEu4upq4coVWLDAve3LjcBZUQgGhgGvSykro9poF9oBXAjxsRDimBBiWwHvCyHE\nVCHEXiHEFm+fzzB1zVQq+lfk/yL/z/Br3XOPuYVsUipRaF/3WhGb2djnNyclQVqa2daYT2Ki6qnj\n6b46sbHq98PuJvEkR88fJebzGEbNG8UdN9zB1hFb6d3IoN4ewM01bmZQi0FMXzud4xeKVsFly9Rq\n1srxBHBeFKYD0cDgnO/PoaqaC+NToGch7/cCGuW8hgMznbTFchw9f5Qvt33JsNbDCA4wvnls7nba\nZrB1K+zdCw/0aElF/4oFjuf0NEOGqFz5774z2xJzuXBB9dUxw28dGal+Pz3tQkr6I4mWM1uyOHkx\n03pN46fBP1GrYi3Dr/vybS9zMeMib698u2gbk1T8y9PtYFzFWVHoIKV8ArgEIKU8DRRaiyelXAoU\nNr21L/BfqVgFVBFCFD8lwETeX/8+V7Ku8GSU+9NQC8JMF1JCglqp3NPPj/Yh7S0jClFRcMMN2oW0\naJESRzOeSH181HXnzYOMDOOvdzHjIiPnjiT2i1jqBtVl3SPreCLqCTwV/mxasyn3tbiPaWumcSL9\nRKH7JiYqN2elSh4xrdg4KwoZQghfUA3GhRA1gZJ2mwkBDuT6PjVn23UIIYbbZzkcN8tZWQBXsq4w\nc91Met7Uk5tr3Oyx65rpQkpIUO2Sa9eG6JBoNh3ZxMUM89N+hFAB54ULVepfWcXeV+e228y5fkwM\nnD0Lv/9u7HU2H9lMuw/aMX3tdJ6JfoY1D6+hea3mxl7UAa90eoX0jHTeWflOgfv88Qfs2WN91xE4\nLwpTge+AWkKIOGA58O8SXtuRlDtMY5FSzpJStpNStqtZs/jDaozg6+1fc+T8Ebd1Q3UWs7KQdu9W\nqxN7wZq9iG394fWeNaQABg9WvX7Mzs4yC3tfnTvvNK+vzh13qGsblZqaLbOZtHISUR9GceriKebf\nP5+3e7xNeb/yxlywCJrVbMbA5gN5d827nEw/6XAfqw7UcYSz4zjjgX8CE4DDwN1SypL+2aUC9XN9\nHwqUvCeth5m6ZiqNqzfmzhs93/xnwAA1zs+TLqRvv1Vf+6vOwtcmsVkg2AzQvDlERJTdQrZNm+DQ\nIXPz4IOC1PwPI+IKh84doufsnjyz4Bl63dSLrSO2mvK3l59XOr3ChSsXmLRqksP3ExOhWTNo2NDD\nhhUDp6s4pJS7pJTTpZTTpJQ73XDtH4EHcrKQooE0KWXxWw+awKrUVaw5uIZRUaPcUhDjKma4kBIS\noEMHCA1V39eqWIsbq95ombgCqNXCypXw119mW+J5rNJXJzZWjZB15wztH3b9QMTMCJbvX877se/z\n3X3fUSOwhvsuUAKa12rOvc3uZerqqZy6mDeUevYsLF1q7YK13Bh2JxNCfAGsBG4WQqQKIR4SQjwm\nhHgsZ5e5wD5gL/AB8LhRthjF1NVTqVy+Mg+0esCU63vahZScDOvXX1sl2IkOjc4zic1sBg1SX7/8\n0lw7zCAxURWQmd1Xp6SDd+K3xhM+ORyf8T40mNSAbp914+6v7iasShgbHt3A8LbDPRZMdpZXOr3C\nuSvnmLQy72phwQLVnNAbXEdgoChIKQdLKetKKf2llKFSyo+klO9JKd/LeV9KKZ+QUt4opWwppfSq\nBnsHzx7k6x1f81DkQwSVN6/PgyddSHbXUf4GeLZQG0fOH2F/2n7jjXCC8HC45Zayl4V07Jjqq2OF\nJ9Ibb4QmTYoXV4jfGs/wn4aTkpaCRHLg7AF+Tf6V2EaxrHxoJU1qNHG/wW6gZe2W3NP0Hqaumcrp\ni6evbk9KgipV1O+kN+B5n0cp4b1175GVncXIqJGm2uFJF1JCArRqpf7gc2Orn1PEZjEX0tatanZw\nWeHnn1WguSRPpLmf0MMnhxO/Nb7Y54qNhSVLVMEWqGrjC1cucPDsQXYc38GKAyv4ec/PfLH1C95b\n9x4Tl0/kxYUv8ljiY6RnpF93vq3HtlLO14JTaXIxtvNYzl4+y+RVkwGV9DB3LvTsqZoTegNeYqa1\nuJR5iffXv0+fm/twQ1Vzm8XmdiG9+qpx1zl0SI11fO2169+LqB1BBb8KrEpdxaAWg4wzwgUGDIDR\no9VqIS7ObGs8Q1KS6qsT6dy8mOuwP6Hbb8gpaSkM/2k4oGYVZ2ZnknYpjTOXzpB2Oeero+8vq6/J\noWfIeDCNRtPOkOmr3s+SWYXa4O/jT0a24wIHq6xECyOidgT9mvRjyuopPG17mj+2VOHYMWus3pxF\ni0Ix+HLblxxPP86oKOO6obrCgAEwcqRyITU3KE3bXiXsaHaCn4+1ithA+dS7dVOi8Prr1u414w6u\nXFGjNwcOLP7/dcyiMdc9oadnpPP37/7Ooz89yoWMomdtBpULokpAFYIDggmuVAW/S3WpdLopPToH\nX91eJaAKweUdfx/gF0DDKQ0d9tNqENygeP8xDzO281i+2/UdU1ZNIevXcfj4qJWCt6BFwUWklExd\nPZXmNZtze8PbzTYHUDfqJ59UqwWjROHbb5WPuFkzx+/bQm28s/IdLmVeIsAvwBgjXGTIEBg2DFav\nhuhos60xluXLVZZLcZ9Iz10+V2BjwyyZxaNtHy3ypl65fOXrmkHetwCW/g/enej89Le4bnF5ViwA\ngf6BxHXzjiVf6zqt6XtzXyavnkzY/NHYbMFUr262Vc6jRcFFlu9fzsYjG3k/9n3LZD/UqaOqV41y\nIZ04Ab/9Bi+8UPA+tlAbGdkZrD+0no4NOrrfiGLQrx88+qhaLZR2UUhKUgVjrvbVOX7hOFNXT2Xa\n2oJbmYUFh/F2j6J7+zgiNlb16Nqwwfk50UNbDgXUymV/2n4aBDcgrlvc1e3ewLjO42gzqw1nAqYy\nodcrZpvjEjrQ7CJT10ylakBV7o+432xT8jBwoMpC2rHD/ef+4QfIynLsOrJjL2JblbrK/QYUk8qV\n1U3pq69K//xmV/vqpJxJ4cm5TxI2OYy4ZXHc3vB2xncZf9284pI+offsqdxZrqamDm05lOTRyWSP\nyyZ5dLJXCQJAZN1IWgXcBbZJdL7Tu6YMaFFwgf1p+/lu53c80uYRl4Z9ewIjs5ASElSaZ2GDQWpX\nqk3DKg0tFVcAlYV09KjKgimt7Nmjeus44zradmwbD3z3ADdOvZH317/P4BaD2fHEDhIGJjC281hm\n9ZlFWHAYAkFYcBiz+swq0Q25Zk21SrPKNDZPUmXTWKhwmkXn3zXbFNeQUnrVq23bttIsnv/leekz\n3kemnEkxzYbC6NRJymbN3HvO06el9PeX8tlni953SMIQWe/tejI7O9u9RpSA9HQpK1eW8sEHzbbE\nOCZNkhKk3Lev4H1+3/+77PN5H8mryIpxFeUz856RB9IOeMS+uDhl3+HDHrmcJbh4UcrAQCnDXoyV\nVSdWlWmX0sw2SQLrpBP3WL1ScJL0jHRmrZ9Fvyb9LJsFYYQLKTFRtUAuzHVkxxZq49C5Qxw4e6Do\nnT1EhQoqtvDtt6qddGkkKclxXx0pJT/v+ZlOn3Si48cdWXFgBeO7jCdldApv93ib0MqhHrHPXjcx\nd65HLmcJfvsN0tPh6chxnL50mmlriho/Yx20KDhJ/JZ4Tl867fFuqK5ghAspIUHlvnfoUPS+Vowr\ngHIhpaWZMw3MaM6eVTeg3AVrmdmZfLH1C1q/35ren/cm+UwyU3pOIWV0CmM7j6V6oGdTYSIiVK+s\nsuRCSkxUDyTDY9vRu1Fv3l75NucunzPbLKfQouAEUkqmrJ5C6zqtubXBrWabUyC5s5DcwfnzalhK\n//7OpRO2qt2KCn4VLNMx1U63bsq3XRo7p/7yi1rJxcaqgTMz186k8buNGfLtEDKyMvi076f8OepP\nRnUYRcVyFU2xUQglWr/8UnpXa7mxty/v1k0Jw7jO4zh18RTT10432zSn0KLgBIuTF7P9+Hae6vCU\nZdJQC2LAAFXE5g4X0rx5cOmSc64jAH9ff9rVa2e5YLOfn3Kt/fTTtZYLpYWkJAiulcZyJtJwSkMe\nn/s4tSrW4vv7vmfb49v4e+u/4+/rb7aZxMaqh4ylS822xHh27lQdeu2B/6iQKHre1JO3VrzF+Svn\nzTXOCbQoOMGU1VOoGVjTMi0cCsOdLqSEBPWE7coEL1uojQ2HN3Ap81LJDXAjQ4Yogfv+e7MtcR+H\nzh7hq5MvkP5oA8YsfpHIupEs+fsSVj60kr5N+prSzr0gbr8dAgI8P7vZDOz/x969r20b13kcJy+e\nZMbaGeYY5QLW+a2xKPtO7+On3T/xaNtHLVOpWxh167rHhXTpkvKL9u0Lvr5F728nOjSajOwMNh7e\nWDID3IzNBmFhpaNz6p+n/uSxxMdoOCWc9NZv0ja4NxuGb+DnoT/TObyzJVezgYFKGBITlXulNJOY\nqBpH1s81Qiw6NJoeN/bgrRVvceFK0e1CzESLQhFMWzMNXx9fRrQfYbYpTuMOF9Ivv6jlvrOuIztW\n7JgK1+Y3L1gAFhvz7TSbjmxicMJgGk9rzCebPqFl1jDE9N0kDvuCyLrF7ILnQWJi1NCdP/4w2xLj\nOH1azaZ21Kl2XOdxHE8/zsx1Mz1vmAtoUSiE81fO89HGjxjQbAD1guqZbY7TuMOFlJAAwcHq6c4V\n6lSqQ3iVcMuJAihRyMqCb74x2xLnkVLyW/Jv9IrvReT7kST9kcRztzxH8lPJkPgetzS5yWv66thv\nlKU5C2n+fPU75qiQ0FbfRvcbuvPmijctvVrQolAIn236jLOXzzKqgzW6oTpLSV1IGRnw449w113F\nG/4eHRptubRUgJYtVcNAq7qQcs8yCJscxjPzn+GWj2+hy2dd2HB4AxO6TWD/0/uZeMdEOF+X9eu9\nZ5oXKPddy5alWxQSE6FGDYiKcvz+uM7jOHbhGO+te8+zhrmAFoUCyJbZvLvmXaJCoq7m33sTJXEh\nLV6slsGuuo7s2EJtpJ5NJfVsavFOYBB2F9KyZbDfYq35808b25+2n0mrJrH35F5m9J5B8lPJvHDr\nC1QJqAJcKwTzpj79oERs+XI4c8ZsS9xPVpaqhenVq+A4XMcGHenWsBtvrHjD4SAhK6BFoQAW/LmA\n3Sd3W2ZmgquUxIWUkAAVK8Kddxbv2rbQnLiCxeoVQIkCqCZ5VsLRLAOAwHKBjGg/ggr+FfJsT0xU\ngcwWLTxloXuIjVXNCRcsMNsS97NqFZw6VfTqzb5aeH/d+54xzEW0KBTA1NVTqVOpDgOaDzDblGJR\nXBdSVpZK24yJUYU3xaFVnVYE+AVYMq5www2qOttqhWwFTRU7kHZ9y5DLl1UiQGys9w0Pio6GatVK\nZ2pqUpJaIfToUfh+t4XdRtfwrryx4g0uZlz0jHEuoEXBAbtP7ObnvT8zot0Iy8+ELQy7C2nnTueP\n+f13NQC+f//iX7ecbzna1m1rybgCqNXCpk2ufS5GU7tSbYfbHfXZ+u03uHDBu+IJdnx9lXtl7lz1\nAFKaSExUD2JVqhS977jO4zhy/giz1s8y3jAX0aLggGlrplHOtxyPtn3UbFNKRHFcSAkJUL583sKb\n4mALtbH+8HouZ1qvr8HAgapth5UCzjUq1LhuW0GzDOx9dVzNDLMKMTFqcNPatWZb4j7274etW50X\n6s7hnekc1pn//P4fyxV6alHIR9qlND7d/CmDWgwq8OnNW6hbF269VU2+cobsbNVNtEcPCAoq2bVt\n9W1cybrCxiPWKmID9bl07apEwQqFVAv3LWTb8W0MbTm0yFkGUipRsPfV8UZ69FArhtKUhWR3h7kS\n+H+1y6scPn+YD9Z/YIxRxUSLQj4+2fQJ56+c99oAc34GDnTehbR2LaSmFj/rKDf2jC0rBptBtb3Y\nuxfWrTPXjmyZzQsLXyAsOIyP7vqoyGlju3apvjre6DqyU60a3HJL6YorJCWpeNXNNzt/TJfwLnQK\n68TE3ydaarWgRSEXWdlZvLvmXTrW70jbem3NNsctuOJCSkhQzeP69Cn5desF1aNBcANWHbRmXKF/\nf1WDYbYL6Zsd37D+8Hpe6/oa5f3KF7m//UbqzaIA6ol60yb1EOLtpKfDokXFC/yP6zyOQ+cO8dGG\nj4wxrhhoUcjF3D1z2Xd6n6VnJriK3YVUlChIqUShWzeoWtU917aF2iy7UqhSRcVNvvrKvIBnRlYG\nY34dQ8taLZ0eeZmYqOYT5O6r443Y3SylYbXw66+qV1hxhLpreFdubXArE5ZPsEz8TYtCLqasnkJo\n5VDubnK32aa4lYEDYdu2wl1ImzfDvn3ucR3ZsYXaOHD2AAfPHnTfSd3I4MFw6JB57Zw/3PAhe0/t\nZUK3Cfj6FN118PRpVfjlbQVrjmjaVM39Lg2ikJSk6no6d3b9WCEE4zqP4+C5g3y00RqrBS0KOWw/\ntp1Ffy3iifZPWKL/vDtxxoX07bcqI6dvX/dd16rN8ezExkKlSua4kM5fOc/438bTKawTvRs5l+q1\nYIFa1Xi76wjU72NsLCxcCBetl6rvNPbA/513qqy94tCtYTduqX+LZVYLWhRymLp6KgF+ATzS5hGz\nTXE7zriQEhJUjnWtWu67bus6rSnvW96y9QqBgXD33apB3pUrnr325FWTOXrhKP+54z9Ot7pOTITq\n1Z0bjeoNxMQoQViyxGxLis/WrSouUhKhtq8WUs+m8smmT9xnXDHRogCcuniK/235H/e3vN/j82s9\nxYABBbuQdu1SPZLc6TqCnCK2em0tu1IAlYV0+rTqbukpTqSf4I3f36Bfk35O99Wy99Xp3du1+RZW\npksXJczenJpqt72kdT3db+hOdGg0E5ZP4EqWh59Q8qFFAeXbvZh50eu6obpCYS6khAT1tSRVzAVh\nC7Wx/tB603/RC+KOO5Q/eNAg5T4LD4f4eGOvGbc0jgsZF4i7/frCtIJYvRpOniwdriM7AQHq809K\nska9SHFISoK2bdVqvCTYVwv70/bz6aZP3WJbcSnzopCZncn0tdPpGt6VlrVbmm2OYdSrV7ALKSFB\n9aQJCXH/daNDo7mcdZlNRza5/+RuYM4c1UsoPV3dmFJSYPhw44Qh+UwyM9bN4MHWD9K0ZlOnj3O2\nr463ERurPvPt2822xHVOnICVK90X+O9xYw86hHTg38v+bepDVJkXhR92/cD+tP2lepVgx5ELad8+\n2LjR/a4jO1bumAowZozq2pmb9HS13QjGLh6Lj/Dh1S6vunRcYqISdWf66ngTdreLN2YhzZunHiTc\ntXqzrxZS0lL47+b/uuekxaDMi8LUNVMJrxJOn8ZuqNiyOI5cSN9+e+09IwipHEL9yvUtG1coaK6C\nEfMWthzdwuwtsxkVNYrQyqFOH3fgAGzZUjpSUfMTEgKRkd4ZV0hMhNq1lfvIXfS8qSft67Unblkc\nGVkZ7juxC5RpUdh0ZBNLU5Yysv1Ip/LEvR1HLqSEBPVH2bChcde11bdZVhQaXN+EFFBxhrQ0917r\nxUUvEhwQzAu3vuDScaWlirkgYmNhxQoVM/EWMjLUSqF3bxWLchf21ULymWTTVgtlWhSmrp5KoH8g\nD7V5yGxTPIbdhbRrFxw8qAaDGBFgzk10SDT70/Zz6NwhYy9UDOLiVAZMbvz84Px5aNZMzZZwB78l\n/8bcPXN58dYXqVrBtZLxxETVV6dJE/fYYjViYlQzRk9mgJWUFSvUQ4MRq7fejXrTrl4701YLZVYU\njl84zudbP+fvrf5+dcRhWSC3C+m7765tMxJ7EZsV6xWGDoVZs9T8YCHU108/hTVr1Kzdfv3U53Oo\nBHompeT5hc8TEhTCk1FPunSsva9OTIz3DdRxlvbtoWZN73IhJSaCvz907+7+cwshGNtpLH+d+YvZ\nW2a7/wJFYKgoCCF6CiF2CyH2CiGuWzMLIRoIIRYLITYKIbYIIUqY7es8s9bP4nLWZZf/SL0duwtp\nzhzlOmraVL2MJLJOJOV8y1k22Dx0KCQnq6fV5GT1ffv2qoPqhAlqIEzTpvDee2ofV/l+1/esPria\n8V3GXzdWsygWL1Z9dUpjPMGOj49yw8ybd33Q36okJam2FiVtMV8QsY1jaVO3DXHL4sjM9uyHYpgo\nCCF8gelAL6AZMFgI0Szfbi8Dc6SUkcAgYIZR9uQmIyuDGetmcOeNd7qUFlhaCA9XLqQlS9QTsNF5\n+eX9ytO2rrWL2Bzh7w8vvKCqVtu1gxEj1I3AlYltmdmZvLjoRZrWaMrfW//dZRtK0lfHm4iNVUWE\nK73gV2TfPvU7YKRQ21cLf57+k/gtBv+B5sPIlUIUsFdKuU9KeQX4EsjfWUcClXP+HQx4xOmcsDOB\nQ+cOlapuqM4SH6/aOthJSzM2L99OdGg06w9bt4itMG66SfXo+eQTlU/fujWMH6/qG4ri002fsvvk\nbv7d7d/4+fi5dF17X53u3YvfV8db6N5dxXK8ITXVU4H/u26+i9Z1WvP6stc9ulowUhRCgNxTx1Nz\ntuXmVeB+IUQqMBdw6MsRQgwXQqwTQqw7fvx4iQ2bsnoKjao1oudNPUt8Lm9jzJjrG5AZmZdvxxZq\n41LmJTYf2WzshQxCCBg2TAXo77kHXn1VZW39/nvBx6RnpPPqklexhdroe7PrnQa3bVPpqKXZdWQn\nOBg6dfKOuEJiohqmc9NNxl7HvlrYe2ovX2z1XNdGI0XBUVgsfzH7YOBTKWUo0Bv4nxDiOpuklLOk\nlO2klO1q1qxZIqPWHFzDqtRVPBn1JD7XX6rU48m8/NxYvWOqs9SqBZ9/ruIM6ekqPjNihOP01XdX\nv8vBcweZeMdEp5ve5cZdfXW8hZgYtRJLTjbbkoI5f165XT2VHty3SV9a1W7l0dWCkXfFVCD3KJBQ\nrncPPQTMAZBSrgQCgOsnmLuRqaunElQuqFj+3dJAQXn5BW13F6GVQwkJCvF6UbDTq5d6kn/6aZW9\n1KzZtWwuUE0WJ/4+kZhGMXQK61Ssa7irr4634A2DdxYuVB11PbV68xE+jO08lj9O/kGdt+rgM96H\n8MnhxG81zt9rpCisBRoJIRoKIcqhAsk/5ttnP9ANQAjRFCUKJfcPFcDhc4eZs30O/xf5f1QuX7no\nA0ohjvLyAwPVdqOx1bdZMi21uFSqBO+8o2o9atZU9R79+6v6j4nLJ5J2KY0J3SYU69z2vjqltWDN\nEY0bQ6NG1nYhJSZC5eTBAVgAAA6BSURBVMpqhegp0jPSEQhOXjyJRJKSlsLwn4YbJgyGiYKUMhMY\nCcwHdqKyjLYLIV4TQtyVs9uzwCNCiM3AF8AwKd3fLzF+azzhk8Op9049MrIzaBBs8GOxhXGUlz9r\nltpuNLZQG8lnkjly/ojxF/Mg7dvD2rXwn/+o9tZNog4wacVU7o/4W7GbLM6bp9Jfy0I8ITcxMSoN\n98IFsy25nuxs5Tbs0UNlpnmKl399GZnP856ekc6YRcYEAg11qksp50opG0spb5RSxuVsGyul/DHn\n3zuklB2llK2klK2llAvcbUP81niG/zSclLSUq9teWfyKocsvq+MoL98TWL05Xknw94d//lO5lILu\nepXMTMmO6a+xY0fxzpeU5P6+Ot5AbKzK6lq0yGxLrmfjRjh82PNCvT/NccCvoO0lpdRHWscsGkN6\nRnqebUaqrKZgIutG4u/jX6pcSPm5XHkHR+t+So9qT/DXxjBat1aZSs6kr9rJzDSmr443cNttqiDM\ninGFpCS1uu7Vy7PXLcizYZTHo9T/ynlaZTUFE+AXQJu6bUpNsNkRLy16iUrlKjH70ZfYuRMGDlQ1\nDa1bw/Llzp1jxQo4c6bsuY4AypVT846tOHgnMVGNQi1hAqTLxHWLI9A/byAw0D+QuG7GBAJLvSh4\nWmU1hWMLtbHu0DrT2gIbyYoDK/hh9w/885Z/UiOwBrVqwezZKs5w8aJ6Cn7sMXXDLwwj++p4AzEx\nKli/2UIlLUePqriRGYH/oS2HMqvPLMKCwxAIwoLDmNVnFkNbGuP3LfWi4GmV1RSOrb6Ni5kX2XzU\nQn/xbkBKyQsLX6BOpTqMjh6d572ePVX+/TPPwAcfqPRV+xwLRxjdV8fq2OsyrJSFNHeu+mrW6m1o\ny6Ekj04me1w2yaOTDRMEKAOi4GmV1RSOfVB9aYsrJO1JYtn+ZYzrPI6K5Spe937FivD222rWcu3a\nqiq6Xz/1RJybfftgx46ylYqan9q1VUaXleIKSUlqIFCrVmZb4gGklF71atu2rdR4L9nZ2bLe2/Xk\nkIQhZpviNjKzMmWLGS1ko6mN5JXMK0Xuf+WKlG+8IWWFClIGBUk5fbqUWVlSzp4tZdWqUoKU9eqp\n78sq/furz0EIKcPCzPssZs+WskEDZUulSt79MwHWSSfusabf5F19aVHwfu756h7ZcHJDs81wG59u\n/FTyKnLOtjkuHbd3r5R33KH+Chs1kjIgQP3b/goM9O6bUHGZPdsan8Xs2eq6ZtvhLpwVBSGtFuIv\ngnbt2sl169aZbYamBLy94m3+8cs/OPLsEWpXqm22OSXiUuYlbp52M7Uq1mLNw2tc7nEkJfzvf/Dg\ng45nNYSFWbsXkBGEh0NKyvXbq1eHyZM9Z8fo0Y5HhHrrz0QIsV5K2a6o/Vzr5avRuIHccYW+TVzv\nHmolZqydwf60/XzS95NiNb0TAh54QHVgdYTRjQqtSEH/55Mn4W9/86wtjijtPxMtChqP07ZeW/x9\n/FmZutKrRSHtUhpxy+K488Y7ub3h7SU6V4MGjp+OjW5UaEUK+izq1YPffvOcHZ07Ox7DWtp/JloU\nNB4nwC+AyLqRXl/E9sbvb6huqN0mlvhccXFq2FF6ruJ7TzUqtBoFfRZvvGH8DIPcvPFG2fyZlPqU\nVI01iQ6JZu3BtV5bxHb43GEmrZrE4BaDiawbWeLzmdmo0GpY5bOwih2eRgeaNabw5bYvGZwwmPXD\n19OmbhuzzXGZEYkj+HDjh+x6Yhc3VrvRbHM0miJxNtCsVwoaU/Dmjql/nPyDDzZ8wGNtH9OCoCl1\naFHQmEKD4AbUrVTXK+MKL//6MgF+Abzc6WWzTdFo3I4WBY0pCCGIDo32unYXaw+u5esdX/OPW/7h\n9TUWGo0jtChoTKO8b3n+PP2nR+bOugMpJc8vfJ6agTV51vas2eZoNIagU1I1phC/NZ7vdqlJ97nn\nzgKWbVa44M8FLE5ezNSeUwkqX0ZbmGpKPXqloDGFMYvGcDkr7zgyK0/Ey5bZvLDoBRpWacij7R41\n2xyNxjD0SkFjCt42Ee/LbV+y6cgmZvebTTnfcmabo9EYhl4paEyhsMl3r/z6CqcunvKgNYVzJesK\nL//6Mq1qt2Jwy8Fmm6PRGIoWBY0pOJqIF+AXQPt67Xl92euETw63jDi8v+59/jrzFxPvmIiP0H8y\nmtKN/g3XmIKjiXgf3vUhqx9ZzZbHttDjph6WEIdzl8/xr6X/omt4V3rc2MMUGzQaT6LbXGgsy9aj\nW/nX0n/x9Y6vCSoXxFMdnuJp29NUq1DNYzaMXzKeV397ldUPryYqJMpj19Vo3I1uc6HxelrWbsmc\nAXPY8tgWet7U0+Mrh2MXjvHWyre4t9m9WhA0ZQYtChrLU5A4vPzry4aKw+tLX+dixkXibi/lvZI1\nmlxoUdB4DfnFIW5ZnGHisO/0Pt5b9x4Pt3mYxtUbu/XcGo2V0aKg8Trs4rB1xFbDxOGVxa/g5+PH\n2M5j3XI+jcZb0KKg8Vpa1GpRoDicTHcwcd1JNh7eyOdbP2d09GjqBdVzo8UajfXRoqDxenKLQ69G\nvfj3sn/TcErDYovDi4tepFqFavyz4z8NsFajsTZaFDSlhha1WvDVvV+xZcSWYovDr3/9yvw/5/PS\nrS9RJaCKwRZrNNZD1yloSi3bjm1TdQ7bv6ZiuYqMihrFM7ZnqB5Y3eH+Uko6fNiBI+eP8MeTfxDg\nF+BhizUa49B1CpoyT+6VQ+9GvZmwfALhU8IZs2iMw5VDws4E1h5ay2tdX9OCoCmzaFHQlHqKEof4\nrfGETQ5jwNcD8Pfxx1f4mm2yRmMa2n2kKXPkdiuV8y1HlswiMzvz6vuB/oHM6jPLssN+NJrioN1H\nGk0B5F45+Pr45hEEsPawH43GaLQoaMosLWq14GLGRYfvWXXYj0ZjNIaKghCipxBitxBirxDihQL2\nGSiE2CGE2C6E+NxIezSa/BQ07KewIUAaTWnGMFEQQvgC04FeQDNgsBCiWb59GgEvAh2llM2B0UbZ\no9E4wtGwn0D/QOK66SZ4mrKJkSuFKGCvlHKflPIK8CXQN98+jwDTpZSnAaSUxwy0R6O5DkfDfnSQ\nWVOW8TPw3CHAgVzfpwId8u3TGEAI8TvgC7wqpZyX/0RCiOHAcIAGDfSyXuNehrYcqkVAo8nByJWC\ncLAtf/6rH9AI6AIMBj4UQlzXW0BKOUtK2U5K2a5mzZpuN1Sj0Wg0CiNFIRWon+v7UOCQg31+kFJm\nSCn/AnajREKj0Wg0JmCkKKwFGgkhGgohygGDgB/z7fM90BVACFED5U7aZ6BNGo1GoykEw0RBSpkJ\njATmAzuBOVLK7UKI14QQd+XsNh84KYTYASwGnpNSFr8Rvkaj0WhKhG5zodFoNGUAZ9tceJ0oCCGO\nAynFPLwGcMKN5ng7+vPIi/48rqE/i7yUhs8jTEpZZKaO14lCSRBCrHNGKcsK+vPIi/48rqE/i7yU\npc9D9z7SaDQazVW0KGg0Go3mKmVNFGaZbYDF0J9HXvTncQ39WeSlzHweZSqmoNFoNJrCKWsrBY1G\no9EUghYFjUaj0VylzIiCMwN/ygpCiPpCiMVCiJ05w42eMtsmsxFC+AohNgohEs22xWyEEFWEEN8I\nIXbl/I7YzLbJLIQQT+f8jWwTQnwhhAgw2yajKROi4MzAnzJGJvCslLIpEA08UcY/D4CnUO1YNDAF\nmCelbAK0oox+LkKIEGAU0E5K2QLV3n+QuVYZT5kQBZwb+FNmkFIellJuyPn3OdQffYi5VpmHECIU\niAE+NNsWsxFCVAY6AR8BSCmvSCnPmGuVqfgBFYQQfkAg13d6LnWUFVFwNPCnzN4EcyOECAcigdXm\nWmIqk4F/AtlmG2IBbgCOA5/kuNM+FEJUNNsoM5BSHgTeAvYDh4E0KeUCc60ynrIiCs4M/ClzCCEq\nAQnAaCnlWbPtMQMhRCxwTEq53mxbLIIf0AaYKaWMBC4AZTIGJ4SoivIoNATqARWFEPeba5XxlBVR\ncGbgT5lCCOGPEoR4KeW3ZttjIh2Bu4QQySi34u1CiNnmmmQqqUCqlNK+cvwGJRJlkTuAv6SUx6WU\nGcC3wC0m22Q4ZUUUnBn4U2YQQoj/b+9+XmwK4ziOvz8oYUSKDWVCScrPjZJS8w9YkMIkayk7ESl7\ndsps1MgsRGZnIaOmLBgZw2TsLJgiG03NgtDH4jxOYzDGlDk383mt7n16ztP31D33+9zn3PN9qNaM\nX9q+1HQ8TbJ92vYa2+1Un4v7tv/72eDv2H4HvJG0sTR1ACMNhtSk18AuSYvLNdPBHLjpvqDpAGaD\n7S+Svm/4Mx+4avtFw2E1aTfQCQxLGiptZ2zfaTCmaB0ngJ4ygXoFHGs4nkbYfiTpFjBI9Y+9p8yB\nchcpcxEREbW5snwUERHTkKQQERG1JIWIiKglKURERC1JISIiakkKEbNI0t5UYo1WlqQQERG1JIWI\nX5B0RNKApCFJXWW/hXFJFyUNSuqTtLL03SbpoaTnknpLzRwkbZB0T9Kzcsz6MnzbhP0KesrTshEt\nIUkhYhJJm4CDwG7b24CvwGFgCTBoewfQD5wvh1wDTtneAgxPaO8BLtveSlUz521p3w6cpNrbYx3V\nE+YRLWFOlLmI+EsdwE7gcZnELwLeU5XWvlH6XAduS1oGLLfdX9q7gZuSlgKrbfcC2P4IUMYbsD1a\n3g8B7cCDf39aEX+WpBDxMwHdtk//0Cidm9RvqhoxUy0JfZrw+iu5DqOFZPko4md9wH5JqwAkrZC0\nlup62V/6HAIe2B4DPkjaU9o7gf6yP8WopH1ljIWSFs/qWUTMQGYoEZPYHpF0FrgraR7wGThOteHM\nZklPgDGq+w4AR4Er5Ut/YlXRTqBL0oUyxoFZPI2IGUmV1IhpkjRuu63pOCL+pSwfRURELb8UIiKi\nll8KERFRS1KIiIhakkJERNSSFCIiopakEBERtW/9thGpXFjHmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2512f52e198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(error_training, \"o-\",color=\"b\",)\n",
    "plt.plot(error_vald, \"o-\",color=\"g\",)\n",
    "plt.title('Model Error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2611607142857143,\n",
       " 0.375,\n",
       " 0.38169642857142855,\n",
       " 0.359375,\n",
       " 0.35714285714285715,\n",
       " 0.35714285714285715,\n",
       " 0.35714285714285715,\n",
       " 0.2611607142857143,\n",
       " 0.38169642857142855,\n",
       " 0.2611607142857143]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-56ba6d98f651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhasil_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "hasil_pred=pred.pop(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-fd61d6c5642a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'pop'"
     ]
    }
   ],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasil_prediksi=[]\n",
    "pred=hasil_pred\n",
    "for a in pred:\n",
    "    if a == 1:\n",
    "        hasil_prediksi.append(\"Draw\")\n",
    "    if a==0:\n",
    "        hasil_prediksi.append(\"Away Win\")\n",
    "    if a==2 :\n",
    "        hasil_prediksi.append(\"Home Win\")\n",
    "                    \n",
    "        \n",
    "# a=[\"a\",\"b\",\"c\"]\n",
    "# b=pred[a]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hasil_prediksi=pd.DataFrame(hasil_prediksi)\n",
    "hasil_prediksi.to_csv(\"C:/Users/Wahyu Nainggolan/Desktop/baru/tena.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Away Win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    Away Win\n",
       "1    Away Win\n",
       "2    Away Win\n",
       "3    Away Win\n",
       "4    Away Win\n",
       "5    Away Win\n",
       "6    Away Win\n",
       "7    Away Win\n",
       "8        Draw\n",
       "9    Away Win\n",
       "10   Away Win\n",
       "11   Away Win\n",
       "12   Away Win\n",
       "13   Away Win\n",
       "14   Away Win\n",
       "15   Away Win\n",
       "16   Away Win\n",
       "17   Away Win\n",
       "18   Away Win\n",
       "19   Away Win\n",
       "20       Draw\n",
       "21   Away Win\n",
       "22   Away Win\n",
       "23   Away Win\n",
       "24   Away Win\n",
       "25   Away Win\n",
       "26   Away Win\n",
       "27   Away Win\n",
       "28       Draw\n",
       "29       Draw\n",
       "..        ...\n",
       "418  Away Win\n",
       "419  Away Win\n",
       "420  Away Win\n",
       "421      Draw\n",
       "422      Draw\n",
       "423  Away Win\n",
       "424  Away Win\n",
       "425  Away Win\n",
       "426  Away Win\n",
       "427  Away Win\n",
       "428  Away Win\n",
       "429  Away Win\n",
       "430  Away Win\n",
       "431  Away Win\n",
       "432  Away Win\n",
       "433  Away Win\n",
       "434  Away Win\n",
       "435  Away Win\n",
       "436  Away Win\n",
       "437  Away Win\n",
       "438  Away Win\n",
       "439      Draw\n",
       "440      Draw\n",
       "441  Away Win\n",
       "442  Away Win\n",
       "443  Away Win\n",
       "444  Away Win\n",
       "445  Away Win\n",
       "446  Away Win\n",
       "447  Away Win\n",
       "\n",
       "[448 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for i in range (len(pred_model_DNN_Val)):\n",
    "    maximum = max(pred_model_DNN_Val[i])\n",
    "    for j in range (len(pred_model_DNN_Val[i])):\n",
    "        if(pred_model_DNN_Val[i][j]==maximum):\n",
    "            pred_model_DNN_Val[i][j]=1\n",
    "        else:\n",
    "            pred_model_DNN_Val[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = np.array(val_y, dtype=np.float32)\n",
    "val_y= val_y.reshape([448,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(val_y)\n",
    "b=pd.DataFrame(hasil_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   438  439  440  441  \\\n",
       "0    2    2    1    2    2    2    2    2    0    2 ...     0    0    0    2   \n",
       "\n",
       "   442  443  444  445  446  447  \n",
       "0    1    2    1    1    2    1  \n",
       "\n",
       "[1 rows x 448 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.07589\n",
      "Mean Squared Error: 1.79018\n",
      "Root Mean Squared Error: 1.33798\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics  \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(val_y, hasil_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(val_y, hasil_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(val_y, hasil_pred)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wahyu Nainggolan\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.31      0.74      0.44       171\n",
      "        1.0       0.00      0.00      0.00       117\n",
      "        2.0       0.00      0.00      0.00       160\n",
      "\n",
      "avg / total       0.12      0.28      0.17       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(classification_report(val_y, hasil_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "y_validation=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in val_y:\n",
    "    if a == 1:\n",
    "        y_validation.append(\"Draw\")\n",
    "    if a==0:\n",
    "        y_validation.append(\"Away Win\")\n",
    "    if a==2 :\n",
    "        y_validation.append(\"Home Win\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  45   0]\n",
      " [117   0   0]\n",
      " [160   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_validation, hasil_prediksi))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2611607142857143,\n",
       " 0.375,\n",
       " 0.38169642857142855,\n",
       " 0.359375,\n",
       " 0.35714285714285715,\n",
       " 0.35714285714285715,\n",
       " 0.35714285714285715,\n",
       " 0.2611607142857143,\n",
       " 0.38169642857142855,\n",
       " 0.2611607142857143]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7723214285714286,\n",
       " 1.1138392857142858,\n",
       " 1.3571428571428572,\n",
       " 0.6919642857142857,\n",
       " 0.6183035714285714,\n",
       " 0.8928571428571429,\n",
       " 0.9620535714285714,\n",
       " 0.9709821428571429,\n",
       " 1.0758928571428572,\n",
       " 0.7790178571428571]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_vald"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
